{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "gdf = gpd.read_file('Results/U2018_CLC2018_V2020_20u1.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OBJECTID', 'Code_18', 'Remark', 'Area_Ha', 'ID', 'Shape_Length',\n",
      "       'Shape_Area', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "111\n",
      "None\n",
      "EU_111\n"
     ]
    }
   ],
   "source": [
    "print(gdf.iloc[0]['Code_18'])\n",
    "print(gdf.iloc[0]['OBJECTID'])\n",
    "print(gdf.iloc[0]['Remark'])\n",
    "print(gdf.iloc[0]['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n"
     ]
    }
   ],
   "source": [
    "coord = Point(-8.5772292, 37.283231)  \n",
    "\n",
    "\n",
    "for index, row in gdf.iterrows():\n",
    "    if row['geometry'].contains(coord):\n",
    "        print(row['Code_18'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 324\n",
      "1 : 142\n",
      "2 : 112\n",
      "3 : 242\n",
      "4 : 243\n",
      "5 : 242\n",
      "6 : 241\n",
      "7 : 512\n",
      "8 : 121\n",
      "9 : 243\n",
      "10 : 242\n",
      "11 : 242\n",
      "12 : 242\n",
      "13 : 112\n",
      "14 : 242\n",
      "15 : 322\n",
      "16 : 112\n",
      "17 : 242\n",
      "18 : 241\n",
      "19 : 242\n",
      "20 : 324\n",
      "21 : 313\n",
      "22 : 243\n",
      "23 : 323\n",
      "24 : 243\n",
      "25 : 241\n",
      "26 : 242\n",
      "27 : 243\n",
      "28 : 242\n",
      "29 : 242\n",
      "30 : 322\n",
      "31 : 322\n",
      "32 : 242\n",
      "33 : 241\n",
      "34 : 211\n",
      "35 : 241\n",
      "36 : 242\n",
      "37 : 211\n",
      "38 : 111\n",
      "39 : 241\n",
      "40 : 242\n",
      "41 : 242\n",
      "42 : 211\n",
      "43 : 242\n",
      "44 : 243\n",
      "45 : 322\n",
      "46 : 241\n",
      "47 : 313\n",
      "48 : 241\n",
      "49 : 211\n",
      "50 : 112\n",
      "51 : 242\n",
      "52 : 211\n",
      "53 : 122\n",
      "54 : 323\n",
      "55 : 242\n",
      "56 : 242\n",
      "57 : 231\n",
      "58 : 244\n",
      "59 : 324\n",
      "60 : 241\n",
      "61 : 112\n",
      "62 : 112\n",
      "63 : 223\n",
      "64 : 324\n",
      "65 : 244\n",
      "66 : 244\n",
      "67 : 112\n",
      "68 : 111\n",
      "69 : 112\n",
      "70 : 131\n",
      "71 : 111\n",
      "72 : 313\n",
      "73 : 242\n",
      "74 : 242\n",
      "75 : 242\n",
      "76 : 211\n",
      "77 : 211\n",
      "78 : 112\n",
      "79 : 112\n",
      "80 : 322\n",
      "81 : 313\n",
      "82 : 241\n",
      "83 : 212\n",
      "84 : 324\n",
      "85 : 241\n",
      "86 : 322\n",
      "87 : 243\n",
      "88 : 512\n",
      "89 : 242\n",
      "90 : 213\n",
      "91 : 112\n",
      "92 : 324\n",
      "93 : 212\n",
      "94 : 112\n",
      "95 : 223\n",
      "96 : 111\n",
      "97 : 324\n",
      "98 : 324\n",
      "99 : 324\n",
      "100 : 324\n",
      "101 : 242\n",
      "102 : 242\n",
      "103 : 242\n",
      "104 : 243\n",
      "105 : 211\n",
      "106 : 221\n",
      "107 : 243\n",
      "108 : 243\n",
      "109 : 211\n",
      "110 : 211\n",
      "111 : 211\n",
      "112 : 211\n",
      "113 : 211\n",
      "114 : 324\n",
      "115 : 243\n",
      "116 : 242\n",
      "117 : 211\n",
      "118 : 211\n",
      "119 : 211\n",
      "120 : 221\n",
      "121 : 211\n",
      "122 : 112\n",
      "123 : 211\n",
      "124 : 211\n",
      "125 : 112\n",
      "126 : 324\n",
      "127 : 242\n",
      "128 : 211\n",
      "129 : 242\n",
      "130 : 324\n",
      "131 : 211\n",
      "132 : 324\n",
      "133 : 211\n",
      "134 : 211\n",
      "135 : 221\n",
      "136 : 242\n",
      "137 : 111\n",
      "138 : 242\n",
      "139 : 242\n",
      "140 : 243\n",
      "141 : 324\n",
      "142 : 243\n",
      "143 : 242\n",
      "144 : 223\n",
      "145 : 242\n",
      "146 : 242\n",
      "147 : 241\n",
      "148 : 112\n",
      "149 : 112\n",
      "150 : 223\n",
      "151 : 211\n",
      "152 : 221\n",
      "153 : 112\n",
      "154 : 324\n",
      "155 : 312\n",
      "156 : 323\n",
      "157 : 112\n",
      "158 : 324\n",
      "159 : 112\n",
      "160 : 322\n",
      "161 : 221\n",
      "162 : 221\n",
      "163 : 242\n",
      "164 : 242\n",
      "165 : 242\n",
      "166 : 242\n",
      "167 : 243\n",
      "168 : 221\n",
      "169 : 312\n",
      "170 : 211\n",
      "171 : 242\n",
      "172 : 112\n",
      "173 : 244\n",
      "174 : 211\n",
      "175 : 111\n",
      "176 : 243\n",
      "177 : 243\n",
      "178 : 311\n",
      "179 : 311\n",
      "180 : 211\n",
      "181 : 112\n",
      "182 : 242\n",
      "183 : 322\n",
      "184 : 211\n",
      "185 : 112\n",
      "186 : 242\n",
      "187 : 324\n",
      "188 : 242\n",
      "189 : 243\n",
      "190 : 242\n",
      "191 : 222\n",
      "192 : 211\n",
      "193 : 243\n",
      "194 : 324\n",
      "195 : 512\n",
      "196 : 121\n",
      "197 : 121\n",
      "198 : 241\n",
      "199 : 121\n",
      "200 : 324\n",
      "201 : 241\n",
      "202 : 312\n",
      "203 : 241\n",
      "204 : 241\n",
      "205 : 241\n",
      "206 : 241\n",
      "207 : 112\n",
      "208 : 241\n",
      "209 : 241\n",
      "210 : 241\n",
      "211 : 322\n",
      "212 : 334\n",
      "213 : 112\n",
      "214 : 112\n",
      "215 : 112\n",
      "216 : 112\n",
      "217 : 242\n",
      "218 : 243\n",
      "219 : 112\n",
      "220 : 324\n",
      "221 : 311\n",
      "222 : 313\n",
      "223 : 324\n",
      "224 : 112\n",
      "225 : 243\n",
      "226 : 243\n",
      "227 : 242\n",
      "228 : 221\n",
      "229 : 112\n",
      "230 : 223\n"
     ]
    }
   ],
   "source": [
    "clc_codes = []\n",
    "for i in range(len(df)):\n",
    "    coord = Point(df.iloc[i]['longitude'], df.iloc[i]['latitude'])\n",
    "    found = False\n",
    "    for index, row in gdf.iterrows():\n",
    "        if row['geometry'].contains(coord):\n",
    "            print(f\"{i} : {row['Code_18']}\")\n",
    "            clc_codes.append(row['Code_18'])\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        clc_codes.append(None)\n",
    "\n",
    "    # Save the DataFrame every 100 iterations\n",
    "    if i % 100 == 0:\n",
    "        temp_df = df.iloc[:i+1].copy()  # Create a new DataFrame that only includes rows up to the current iteration\n",
    "        temp_df['CLC_CODE'] = clc_codes\n",
    "        temp_df.to_csv('NaturalFiresTOPOGRAPHY.csv', index=False)\n",
    "\n",
    "# Save the DataFrame one last time at the end to make sure all changes are saved\n",
    "df['CLC_CODE'] = clc_codes\n",
    "df.to_csv('NaturalFiresTOPOGRAPHY.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in gdf:  Index(['OBJECTID', 'Code_18', 'Remark', 'Area_Ha', 'ID', 'Shape_Length',\n",
      "       'Shape_Area', 'geometry'],\n",
      "      dtype='object')\n",
      "Columns in joined:  Index(['date', 'latitude', 'longitude', 'slope', 'roughness', 'aspect',\n",
      "       'geometry', 'index_right', 'OBJECTID', 'Code_18', 'Remark', 'Area_Ha',\n",
      "       'ID', 'Shape_Length', 'Shape_Area'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3493: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "/tmp/ipykernel_17092/1911711095.py:17: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  joined = sjoin(points, gdf, how='left', op='within')\n"
     ]
    }
   ],
   "source": [
    "from geopandas.tools import sjoin\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('LocationsWFire.csv')\n",
    "\n",
    "# Create a new GeoDataFrame from df that includes a 'geometry' column with the coordinates\n",
    "points = geopandas.GeoDataFrame(df, geometry=geopandas.points_from_xy(df.longitude, df.latitude))\n",
    "\n",
    "# Create a spatial index for gdf\n",
    "gdf.sindex\n",
    "\n",
    "# Print out the columns of gdf\n",
    "print(\"Columns in gdf: \", gdf.columns)\n",
    "\n",
    "# Use spatial join to find the polygons that contain each point\n",
    "joined = sjoin(points, gdf, how='left', op='within')\n",
    "\n",
    "# Print out the columns of joined\n",
    "print(\"Columns in joined: \", joined.columns)\n",
    "\n",
    "# The 'Code_18' values for each point are now in the 'Code_18_right' column of 'joined'\n",
    "df['CLC_CODE'] = joined['Code_18']\n",
    "\n",
    "df.to_csv('LocationsWFire.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m longitude \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m     32\u001b[0m coord \u001b[38;5;241m=\u001b[39m Point(longitude, latitude)  \n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m gdf\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcontains(coord):\n\u001b[1;32m     35\u001b[0m         new_clc_code \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCode_18\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:1542\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1540\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1542\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1544\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/geodataframe.py:1636\u001b[0m, in \u001b[0;36mGeoDataFrame._constructor_sliced.<locals>._geodataframe_constructor_sliced\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_geodataframe_constructor_sliced\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;124;03m    A specialized (Geo)Series constructor which can fall back to a\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;124;03m    Series if a certain operation does not produce geometries:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;124;03m      checking the identity of the index)\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1636\u001b[0m     srs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1637\u001b[0m     is_row_proxy \u001b[38;5;241m=\u001b[39m srs\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_geometry_type(srs) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_row_proxy:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:583\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    581\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/construction.py:606\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    604\u001b[0m subarr \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 606\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    608\u001b[0m         object_index\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_pyarrow_string_dtype()\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(subarr)\n\u001b[1;32m    611\u001b[0m     ):\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;66;03m# Avoid inference when string option is set\u001b[39;00m\n\u001b[1;32m    613\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1190\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_non_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_if_all_nat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mM8[ns]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('LocationsWFire.csv')\n",
    "\n",
    "clc_err = [-1]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    date = df.iloc[i]['date']\n",
    "    #district = df.iloc[i]['district']\n",
    "    #municipality = df.iloc[i]['municipality']\n",
    "    #parish = df.iloc[i]['parish']\n",
    "    #local = df.iloc[i]['local']\n",
    "    latitude = float(df.iloc[i]['latitude'])\n",
    "    longitude = float(df.iloc[i]['longitude'])\n",
    "\n",
    "\n",
    "    clc_code = df.iloc[i]['CLC_CODE']\n",
    "    if pd.isna(clc_code):\n",
    "        clc_code = -1\n",
    "    else:\n",
    "        clc_code = int(clc_code)\n",
    "\n",
    "    #if(clc_code in clc_err):\n",
    "    #        print(f\"{i} : {clc_code}\")\n",
    "    #        #print(f\"{date},{district},{municipality},{parish},{local},{latitude},{longitude}\")\n",
    "    #        print(f\"{date},{latitude},{longitude}\")\n",
    "    #        continue\n",
    "    \n",
    "    while(clc_code in clc_err):\n",
    "            latitude += 0.001\n",
    "            longitude += 0.001\n",
    "            coord = Point(longitude, latitude)  \n",
    "            for index, row in gdf.iterrows():\n",
    "                if row['geometry'].contains(coord):\n",
    "                    new_clc_code = row['Code_18']\n",
    "                    break\n",
    "\n",
    "            if pd.isna(new_clc_code):\n",
    "                new_clc_code = -1\n",
    "            else:\n",
    "                new_clc_code = int(new_clc_code)\n",
    "\n",
    "            if new_clc_code not in clc_err:\n",
    "                clc_code = new_clc_code\n",
    "                updated = True\n",
    "\n",
    "    if(updated):\n",
    "            print(f\"{i} : {clc_code}\")\n",
    "            df.at[i, 'CLC_CODE'] = clc_code\n",
    "            updated = False\n",
    "\n",
    "\n",
    "    '''\n",
    "    if(int(date.split(\"-\")[0]) < 2013):\n",
    "        \n",
    "        try:\n",
    "            clc_code = int(df.iloc[i]['CLC_CODE'])\n",
    "        except:\n",
    "            clc_code = -1\n",
    "    \n",
    "        while(clc_code in clc_err):\n",
    "            latitude += 0.0001\n",
    "            longitude += 0.0001\n",
    "            coord = Point(longitude, latitude)  \n",
    "            for index, row in gdf.iterrows():\n",
    "                if row['geometry'].contains(coord):\n",
    "                    #print(row['Code_18'])\n",
    "                    clc_code = row['Code_18']\n",
    "                    break\n",
    "                    \n",
    "        print(f\"{i} : {clc_code}\")\n",
    "        df.at[i, 'CLC_CODE'] = clc_code\n",
    "        '''\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 : -1\n",
      "2006-7-13,37.17454267618904,-7.401703836851796\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Point\n",
    "from geopandas.tools import sjoin\n",
    "import geopandas\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "gdf.sindex\n",
    "\n",
    "df = pd.read_csv('LocationsWFire.csv')\n",
    "\n",
    "clc_err = [-1]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    date = df.iloc[i]['date']\n",
    "    #district = df.iloc[i]['district']\n",
    "    #municipality = df.iloc[i]['municipality']\n",
    "    #parish = df.iloc[i]['parish']\n",
    "    #local = df.iloc[i]['local']\n",
    "    latitude = float(df.iloc[i]['latitude'])\n",
    "    longitude = float(df.iloc[i]['longitude'])\n",
    "    updated = False\n",
    "\n",
    "    \n",
    "    clc_code = df.iloc[i]['CLC_CODE']\n",
    "    if pd.isna(clc_code):\n",
    "        clc_code = -1\n",
    "    else:\n",
    "        clc_code = int(clc_code)\n",
    "\n",
    "    \n",
    "    if(clc_code in clc_err):\n",
    "            print(f\"{i} : {clc_code}\")\n",
    "            #print(f\"{date},{district},{municipality},{parish},{local},{latitude},{longitude}\")\n",
    "            print(f\"{date},{latitude},{longitude}\")\n",
    "            continue\n",
    "    \n",
    "\n",
    "\n",
    "    '''\n",
    "    max_iterations = 1000  # Set a limit to the number of iterations\n",
    "    iteration = 0\n",
    "\n",
    "    while(clc_code in clc_err and iteration < max_iterations):\n",
    "        latitude += 0.001\n",
    "        longitude += 0.001\n",
    "        coord = Point(longitude, latitude)  \n",
    "        point = geopandas.GeoDataFrame([{'geometry': coord}])\n",
    "        joined = sjoin(point, gdf, how='left', op='within')\n",
    "        if joined.empty:\n",
    "            break\n",
    "        \n",
    "        new_clc_code = joined.iloc[0]['Code_18']\n",
    "        if pd.isna(new_clc_code):\n",
    "            new_clc_code = -1\n",
    "        else:\n",
    "            new_clc_code = int(new_clc_code)\n",
    "        if new_clc_code not in clc_err:\n",
    "            clc_code = new_clc_code\n",
    "            updated = True\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    if(updated):\n",
    "        print(f\"{i} : {clc_code}\")\n",
    "        df.at[i, 'CLC_CODE'] = clc_code\n",
    "        updated = False\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('LocationsWFire.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013,2013-09-04,Coimbra,Pampilhosa da Serra,Vidual,Vidual de Baixo,40.0939339998033,-7.85871599992116,512.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('NaturalFiresTOPOGRAPHY_mean_elev.csv')\n",
    "\n",
    "for i in range(len(df)):\n",
    "    #year,date,district,municipality,parish,local,latitude,longitude\n",
    "    year = df.iloc[i]['year']\n",
    "    date = df.iloc[i]['date']\n",
    "    district = df.iloc[i]['district']\n",
    "    municipality = df.iloc[i]['municipality']\n",
    "    parish = df.iloc[i]['parish']\n",
    "    local = df.iloc[i]['local']\n",
    "    lat = df.iloc[i]['latitude']\n",
    "    lon = df.iloc[i]['longitude']\n",
    "    clc = df.iloc[i]['CLC_CODE']\n",
    "\n",
    "    if(int(clc) > 400):\n",
    "\n",
    "        print(f\"{year},{date},{district},{municipality},{parish},{local},{lat},{lon},{clc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332\n"
     ]
    }
   ],
   "source": [
    "#,,,,,,,,,,,\n",
    "\n",
    "#40.0926491,-7.8620043\n",
    "40.0939339998033,-7.85871599992116\n",
    "coord = Point(-7.8620043, 40.0926491)  \n",
    "for index, row in gdf.iterrows():\n",
    "    if row['geometry'].contains(coord):\n",
    "        print(row['Code_18'])\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
