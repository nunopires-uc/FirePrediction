{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "\n",
    "dfTreesDRP = pd.read_csv('TreesPortugueseTerritoryDropped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistanceTwoPoints(lat1, lon1, lat2, lon2):\n",
    "    R = 6371e3  # Radius of the Earth in meters\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(delta_phi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    return R * c  # Distance in meters\n",
    "\n",
    "\n",
    "def check_locality(row):\n",
    "    parish = str(row['parish']).lower()\n",
    "    district = str(row['district']).lower()\n",
    "    unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) & \n",
    "                              (dfTreesDRP['stateProvince'].str.lower() == district)]['scientificName'].unique()\n",
    "    return '; '.join(unique_names)\n",
    "\n",
    "\n",
    "def check_locality2(row):\n",
    "    concelho = str(row['municipality']).lower()\n",
    "    district = str(row['district']).lower()\n",
    "    unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(concelho, na=False)) & \n",
    "                              (dfTreesDRP['stateProvince'].str.lower().str.contains(district, na=False))]['scientificName'].unique()\n",
    "    \n",
    "    if 'scientificNames' in row and not pd.isna(row['scientificNames']) and row['scientificNames'] != '':\n",
    "        existing_names = row['scientificNames'].split('; ')\n",
    "        new_names = [name for name in unique_names if name not in existing_names]\n",
    "        return row['scientificNames'] + '; ' + '; '.join(new_names)\n",
    "    else:\n",
    "        return '; '.join(unique_names)\n",
    "\n",
    "def check_district(row, precision=120):\n",
    "    if 'scientificNames' in row and row['scientificNames'] != '':\n",
    "        return row['scientificNames']\n",
    "    \n",
    "    district = str(row['district']).lower()\n",
    "    lat1 = row['latitude']\n",
    "    lon1 = row['longitude']\n",
    "    \n",
    "    # Filter dfTreesDRP based on 'locality' and 'stateProvince'\n",
    "    filtered_df = dfTreesDRP[(dfTreesDRP['stateProvince'].str.lower() == district)]\n",
    "    \n",
    "    # Calculate the distance for each row in the filtered DataFrame\n",
    "    filtered_df['distance'] = filtered_df.apply(lambda x: DistanceTwoPoints(lat1, lon1, x['decimalLatitude'], x['decimalLongitude']), axis=1)\n",
    "    \n",
    "    # Filter the DataFrame based on the distance\n",
    "    close_points_df = filtered_df[filtered_df['distance'] < precision]\n",
    "    \n",
    "    # Get the unique 'scientificName' values\n",
    "    unique_names = close_points_df['scientificName'].unique()\n",
    "    \n",
    "    return '; '.join(unique_names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_districtCoordSingular(row, precision=500):\n",
    "    if 'scientificNames' in row and row['scientificNames'] != '':\n",
    "        return row['scientificNames']\n",
    "    \n",
    "    district = str(row['district']).lower()\n",
    "    lat1 = row['latitude']\n",
    "    lon1 = row['longitude']\n",
    "    \n",
    "    # Filter dfTreesDRP based on 'locality' and 'stateProvince'\n",
    "    filtered_df = dfTreesDRP[(dfTreesDRP['stateProvince'].str.lower() == district)]\n",
    "    \n",
    "    # Calculate the distance for each row in the filtered DataFrame\n",
    "    filtered_df['distance'] = filtered_df.apply(lambda x: DistanceTwoPoints(lat1, lon1, x['decimalLatitude'], x['decimalLongitude']), axis=1)\n",
    "    \n",
    "    # Filter the DataFrame based on the distance\n",
    "    close_points_df = filtered_df[filtered_df['distance'] < precision]\n",
    "    \n",
    "    # If there are no close points, return an empty list\n",
    "    if close_points_df.empty:\n",
    "        return []\n",
    "    \n",
    "    # Sort the DataFrame by the 'distance' column\n",
    "    close_points_df = close_points_df.sort_values('distance')\n",
    "    \n",
    "    # Get the 'scientificName' and 'distance' of the 5 closest points\n",
    "    closest_points = close_points_df.iloc[:5][['scientificName', 'distance']].apply(tuple, axis=1).tolist()\n",
    "    \n",
    "    return closest_points\n",
    "\n",
    "\n",
    "def check_districtCoord(row, precision=500):\n",
    "    if 'scientificNames' in row and row['scientificNames'] != '':\n",
    "        return row['scientificNames']\n",
    "    \n",
    "    district = str(row['district']).lower()\n",
    "    lat1 = row['latitude']\n",
    "    lon1 = row['longitude']\n",
    "    \n",
    "    # Filter dfTreesDRP based on 'locality' and 'stateProvince'\n",
    "    filtered_df = dfTreesDRP[(dfTreesDRP['stateProvince'].str.lower().str == district)]\n",
    "    \n",
    "    # Calculate the distance for each row in the filtered DataFrame\n",
    "    filtered_df['distance'] = filtered_df.apply(lambda x: DistanceTwoPoints(lat1, lon1, x['decimalLatitude'], x['decimalLongitude']), axis=1)\n",
    "    \n",
    "    # Filter the DataFrame based on the distance\n",
    "    close_points_df = filtered_df[filtered_df['distance'] < precision]\n",
    "    \n",
    "    # If there are no close points, return an empty string\n",
    "    if close_points_df.empty:\n",
    "        return ''\n",
    "    \n",
    "    # Sort the DataFrame by the 'distance' column\n",
    "    close_points_df = close_points_df.sort_values('distance')\n",
    "    \n",
    "    # Get the unique 'scientificName' values of the 5 closest points\n",
    "    unique_names = close_points_df.iloc[:5]['scientificName'].unique()\n",
    "    \n",
    "    return '; '.join(unique_names)\n",
    "\n",
    "\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# Create a KDTree from the coordinates in dfTreesDRP\n",
    "tree = KDTree(dfTreesDRP[['decimalLatitude', 'decimalLongitude']])\n",
    "\n",
    "def check_byCoord(row, precision=120):\n",
    "    lat1 = row['latitude']\n",
    "    lon1 = row['longitude']\n",
    "    \n",
    "    # Query the tree for the indices of the points within 'precision' distance\n",
    "    indices = tree.query_ball_point([lat1, lon1], precision)\n",
    "    \n",
    "    # If there are no close points, return the existing scientificNames or an empty string\n",
    "    if not indices:\n",
    "        return row['scientificNames'] if 'scientificNames' in row and not pd.isna(row['scientificNames']) else ''\n",
    "    \n",
    "    # Get the unique 'scientificName' values of the 5 closest points\n",
    "    close_points_df = dfTreesDRP.iloc[indices]\n",
    "    close_points_df['distance'] = close_points_df.apply(lambda x: DistanceTwoPoints(lat1, lon1, x['decimalLatitude'], x['decimalLongitude']), axis=1)\n",
    "    close_points_df = close_points_df.sort_values('distance').iloc[:5]\n",
    "    unique_names = close_points_df['scientificName'].unique()\n",
    "    \n",
    "    # If 'scientificNames' exists and is not NaN or empty, append new unique names to it\n",
    "    if 'scientificNames' in row and not pd.isna(row['scientificNames']) and row['scientificNames'] != '':\n",
    "        existing_names = row['scientificNames'].split('; ')\n",
    "        new_names = [name for name in unique_names if name not in existing_names]\n",
    "        return row['scientificNames'] + '; ' + '; '.join(new_names)\n",
    "    else:\n",
    "        return '; '.join(unique_names)\n",
    "\n",
    "\n",
    "def checkNearestPoint(row):\n",
    "    if 'scientificNames' in row and row['scientificNames'] != '':\n",
    "        return row['scientificNames']\n",
    "    \n",
    "    district = str(row['district']).lower()\n",
    "    lat1 = row['latitude']\n",
    "    lon1 = row['longitude']\n",
    "\n",
    "    filtered_df = dfTreesDRP[(dfTreesDRP['stateProvince'].str.lower().str == district)]\n",
    "\n",
    "    filtered_df['distance'] = filtered_df.apply(lambda x: DistanceTwoPoints(lat1, lon1, x['decimalLatitude'], x['decimalLongitude']), axis=1)\n",
    "\n",
    "    filtered_df = filtered_df.sort_values('distance')\n",
    "    \n",
    "    # Get the 'scientificName' and 'distance' of the nearest point\n",
    "    nearest_name = filtered_df.iloc[0]['scientificName']\n",
    "    nearest_distance = filtered_df.iloc[0]['distance']\n",
    "    \n",
    "    return nearest_name, nearest_distance\n",
    "\n",
    "\n",
    "def checkNearestPointCoord(row, precision=120):\n",
    "    if 'scientificNames' in row and row['scientificNames'] != '':\n",
    "        return row['scientificNames']\n",
    "    \n",
    "    lat1 = row['latitude']\n",
    "    lon1 = row['longitude']\n",
    "    \n",
    "    \n",
    "    # Calculate the distance for each row in the filtered DataFrame\n",
    "    dfTreesDRP['distance'] = dfTreesDRP.apply(lambda x: DistanceTwoPoints(lat1, lon1, x['decimalLatitude'], x['decimalLongitude']), axis=1)\n",
    "    \n",
    "    # Filter the DataFrame based on the distance\n",
    "    close_points_df = dfTreesDRP[dfTreesDRP['distance'] < precision]\n",
    "    \n",
    "    # If there are no close points, return an empty string\n",
    "    if close_points_df.empty:\n",
    "        return ''\n",
    "    \n",
    "    # Sort the DataFrame by the 'distance' column\n",
    "    close_points_df = close_points_df.sort_values('distance')\n",
    "    \n",
    "    # Get the unique 'scientificName' values of the 5 closest points\n",
    "    unique_names = close_points_df.iloc[:5]['scientificName'].unique()\n",
    "    \n",
    "    return '; '.join(unique_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 0: 200\n",
      "Non empty count in chunk 0: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 1: 195\n",
      "Non empty count in chunk 1: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 2: 201\n",
      "Non empty count in chunk 2: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 3: 135\n",
      "Non empty count in chunk 3: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 4: 105\n",
      "Non empty count in chunk 4: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 5: 107\n",
      "Non empty count in chunk 5: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 6: 158\n",
      "Non empty count in chunk 6: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 7: 168\n",
      "Non empty count in chunk 7: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 8: 165\n",
      "Non empty count in chunk 8: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 9: 148\n",
      "Non empty count in chunk 9: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 10: 154\n",
      "Non empty count in chunk 10: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 11: 162\n",
      "Non empty count in chunk 11: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 12: 151\n",
      "Non empty count in chunk 12: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 13: 157\n",
      "Non empty count in chunk 13: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 14: 156\n",
      "Non empty count in chunk 14: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 15: 158\n",
      "Non empty count in chunk 15: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 16: 148\n",
      "Non empty count in chunk 16: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 17: 169\n",
      "Non empty count in chunk 17: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 18: 180\n",
      "Non empty count in chunk 18: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 19: 176\n",
      "Non empty count in chunk 19: 26\n",
      "Locality\n",
      "3193\n",
      "847\n"
     ]
    }
   ],
   "source": [
    "_year = 2022\n",
    "dfFires = pd.read_csv(f\"Dataset/b{_year}.csv\")\n",
    "dfTreesDRP = pd.read_csv('TreesPortugueseTerritoryDropped.csv')\n",
    "print(len(dfFires))\n",
    "\n",
    "\n",
    "num_chunks = 20\n",
    "\n",
    "# Split the DataFrame into smaller chunks\n",
    "chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "# Apply the function to each chunk\n",
    "for i in range(num_chunks):\n",
    "    chunks[i]['scientificNames'] = chunks[i].apply(check_locality, axis=1)\n",
    "    empty_count = (chunks[i]['scientificNames'] == '').sum()\n",
    "    print(f'Empty count in chunk {i}: {empty_count}')\n",
    "    non_empty_count = (chunks[i]['scientificNames'] != '').sum()\n",
    "    print(f'Non empty count in chunk {i}: {non_empty_count}')\n",
    "from geopandas.tools import sjoin\n",
    "    chunks[i].to_csv(f'DatasetWTrees/PreviousVersions/check_locality/{_year}_chunk_{i}.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "dfFires = pd.concat(chunks)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Locality\")\n",
    "empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "print(empty_count)\n",
    "\n",
    "non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "print(non_empty_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFires.to_csv(f'DatasetWTrees/PreviousVersions/{_year}_checklocality.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk 0: 90\n",
      "Non empty count in chunk 0: 35\n",
      "Empty count in chunk 1: 85\n",
      "Non empty count in chunk 1: 40\n",
      "Empty count in chunk 2: 91\n",
      "Non empty count in chunk 2: 34\n",
      "Empty count in chunk 3: 85\n",
      "Non empty count in chunk 3: 40\n",
      "Empty count in chunk 4: 85\n",
      "Non empty count in chunk 4: 40\n",
      "Empty count in chunk 5: 102\n",
      "Non empty count in chunk 5: 23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Apply the function to each chunk\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_chunks):\n\u001b[0;32m---> 16\u001b[0m     chunks[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_locality2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     empty_count \u001b[38;5;241m=\u001b[39m (chunks[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpty count in chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mempty_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10346\u001b[0m )\n\u001b[0;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[32], line 25\u001b[0m, in \u001b[0;36mcheck_locality2\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     23\u001b[0m concelho \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmunicipality\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     24\u001b[0m district \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m---> 25\u001b[0m unique_names \u001b[38;5;241m=\u001b[39m dfTreesDRP[(\u001b[43mdfTreesDRP\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocality\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(concelho, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     26\u001b[0m                           (dfTreesDRP[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstateProvince\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(district, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m row \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     29\u001b[0m     existing_names \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/strings/accessor.py:137\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/strings/accessor.py:3194\u001b[0m, in \u001b[0;36mStringMethods.lower\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3191\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcasemethods\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m%\u001b[39m _doc_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   3192\u001b[0m \u001b[38;5;129m@forbid_nonstring_types\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   3193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlower\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 3194\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_lower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_result(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/strings/object_array.py:444\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_lower\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_str_lower\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/strings/object_array.py:75\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[0;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m     74\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m map_convert \u001b[38;5;241m=\u001b[39m convert \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(mask)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:178\u001b[0m, in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m NDFrame:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:207\u001b[0m, in \u001b[0;36m_isna\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_can_hold_na:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:292\u001b[0m, in \u001b[0;36m_isna_array\u001b[0;34m(values, inf_as_na)\u001b[0m\n\u001b[1;32m    290\u001b[0m     result \u001b[38;5;241m=\u001b[39m _isna_recarray_dtype(values, inf_as_na\u001b[38;5;241m=\u001b[39minf_as_na)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_string_or_object_np_dtype(values\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m--> 292\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_isna_string_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# this is the NaT pattern\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m iNaT\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:313\u001b[0m, in \u001b[0;36m_isna_string_dtype\u001b[0;34m(values, inf_as_na)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m--> 313\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mlibmissing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnaobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# 0-D, reached via e.g. mask_missing\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m libmissing\u001b[38;5;241m.\u001b[39misnaobj(values\u001b[38;5;241m.\u001b[39mravel(), inf_as_na\u001b[38;5;241m=\u001b[39minf_as_na)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#1916\n",
    "#583\n",
    "\n",
    "_year = 2022\n",
    "#dfFires = pd.read_csv(f\"Dataset/b{_year}.csv\")\n",
    "dfFires = pd.read_csv(f\"DatasetWTrees/PreviousVersions/{_year}_checklocality.csv\")\n",
    "dfTreesDRP = pd.read_csv('TreesPortugueseTerritoryDropped.csv')\n",
    "\n",
    "num_chunks = 20\n",
    "\n",
    "# Split the DataFrame into smaller chunks\n",
    "chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "# Apply the function to each chunk\n",
    "for i in range(num_chunks):\n",
    "    chunks[i]['scientificNames'] = chunks[i].apply(check_locality2, axis=1)\n",
    "    empty_count = (chunks[i]['scientificNames'] == '').sum()\n",
    "    print(f'Empty count in chunk {i}: {empty_count}')\n",
    "    non_empty_count = (chunks[i]['scientificNames'] != '').sum()\n",
    "    print(f'Non empty count in chunk {i}: {non_empty_count}')\n",
    "\n",
    "    chunks[i].to_csv(f'DatasetWTrees/PreviousVersions/check_locality2/{_year}_chunk_{i}.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "dfFires = pd.concat(chunks)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Locality\")\n",
    "empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "print(empty_count)\n",
    "\n",
    "non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "print(non_empty_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFires.to_csv(f'DatasetWTrees/PreviousVersions/{_year}_checklocality2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3168/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Apply the function to each chunk\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_chunks):\n\u001b[0;32m---> 14\u001b[0m     chunks[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_locality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     empty_count \u001b[38;5;241m=\u001b[39m (chunks[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpty count in chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mempty_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10346\u001b[0m )\n\u001b[0;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m, in \u001b[0;36mcheck_locality\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     15\u001b[0m parish \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparish\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     16\u001b[0m district \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m---> 17\u001b[0m unique_names \u001b[38;5;241m=\u001b[39m dfTreesDRP[(\u001b[43mdfTreesDRP\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocality\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(parish, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     18\u001b[0m                           (dfTreesDRP[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstateProvince\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m district)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(unique_names)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/strings/accessor.py:137\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/strings/accessor.py:3194\u001b[0m, in \u001b[0;36mStringMethods.lower\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3191\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcasemethods\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m%\u001b[39m _doc_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   3192\u001b[0m \u001b[38;5;129m@forbid_nonstring_types\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   3193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlower\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 3194\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_lower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_result(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/strings/object_array.py:444\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_lower\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_str_lower\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/strings/object_array.py:78\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[0;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[1;32m     76\u001b[0m map_convert \u001b[38;5;241m=\u001b[39m convert \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(mask)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_convert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     p_err \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m((takes)|(missing)) (?(2)from \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ to )?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(?(3)required )positional arguments?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2903\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mlib.pyx:2543\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numeric.py:290\u001b[0m, in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_full_dispatcher\u001b[39m(shape, fill_value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, like\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(like,)\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;129m@set_array_function_like_doc\u001b[39m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfull\u001b[39m(shape, fill_value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m, like\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    Return a new array of given shape and type, filled with `fill_value`.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m \n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _year in range(2013, 2023):\n",
    "    dfFires = pd.read_csv(f\"Dataset/b{_year}.csv\")\n",
    "    dfTreesDRP = pd.read_csv('TreesPortugueseTerritoryDropped.csv')\n",
    "    print(len(dfFires))\n",
    "\n",
    "\n",
    "    num_chunks = 20\n",
    "\n",
    "    # Split the DataFrame into smaller chunks\n",
    "    chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "    # Apply the function to each chunk\n",
    "    for i in range(num_chunks):\n",
    "        chunks[i]['scientificNames'] = chunks[i].apply(check_locality, axis=1)\n",
    "        empty_count = (chunks[i]['scientificNames'] == '').sum()\n",
    "        print(f'Empty count in chunk {i}: {empty_count}')\n",
    "        non_empty_count = (chunks[i]['scientificNames'] != '').sum()\n",
    "        print(f'Non empty count in chunk {i}: {non_empty_count}')\n",
    "\n",
    "        chunks[i].to_csv(f'DatasetWTrees/PreviousVersions/check_locality/{_year}_chunk_{i}.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "    dfFires = pd.concat(chunks)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Locality\")\n",
    "    empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "    print(empty_count)\n",
    "\n",
    "    non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "    print(non_empty_count)\n",
    "\n",
    "    dfFires.to_csv(f'DatasetWTrees/PreviousVersions/{_year}_checklocality.csv', index=False)\n",
    "\n",
    "\n",
    "    dfFires = pd.read_csv(f\"DatasetWTrees/PreviousVersions/{_year}_checklocality.csv\")\n",
    "\n",
    "    num_chunks = 20\n",
    "\n",
    "    # Split the DataFrame into smaller chunks\n",
    "    chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "    # Apply the function to each chunk\n",
    "    for i in range(num_chunks):\n",
    "        chunks[i]['scientificNames'] = chunks[i].apply(check_locality2, axis=1)\n",
    "        empty_count = (chunks[i]['scientificNames'] == '').sum()\n",
    "        print(f'Empty count in chunk {i}: {empty_count}')\n",
    "        non_empty_count = (chunks[i]['scientificNames'] != '').sum()\n",
    "        print(f'Non empty count in chunk {i}: {non_empty_count}')\n",
    "\n",
    "        chunks[i].to_csv(f'DatasetWTrees/PreviousVersions/check_locality2/{_year}_chunk_{i}.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "    dfFires = pd.concat(chunks)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Locality\")\n",
    "    empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "    print(empty_count)\n",
    "\n",
    "    non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "    print(non_empty_count)\n",
    "\n",
    "    dfFires.to_csv(f'DatasetWTrees/PreviousVersions/{_year}_checklocality2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Empty count in chunk 0: 0\n",
      "Non empty count in chunk 0: 125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Apply the function to each chunk\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_chunks):\n\u001b[0;32m---> 19\u001b[0m     chunks[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_byCoord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     empty_count \u001b[38;5;241m=\u001b[39m (chunks[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpty count in chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mempty_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10346\u001b[0m )\n\u001b[0;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[32], line 137\u001b[0m, in \u001b[0;36mcheck_byCoord\u001b[0;34m(row, precision)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m row \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientificNames\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Get the unique 'scientificName' values of the 5 closest points\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m close_points_df \u001b[38;5;241m=\u001b[39m \u001b[43mdfTreesDRP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    138\u001b[0m close_points_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m close_points_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: DistanceTwoPoints(lat1, lon1, x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecimalLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecimalLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    139\u001b[0m close_points_df \u001b[38;5;241m=\u001b[39m close_points_df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m5\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1192\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1191\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1744\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1748\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1715\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;124;03mReturn Series values by list or array of integers.\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;124;03m`axis` can only be zero.\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:4147\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4136\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   4137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   4138\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4139\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4140\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4148\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:4127\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4122\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4123\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4124\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4125\u001b[0m     )\n\u001b[0;32m-> 4127\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4129\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4133\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4134\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:895\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    892\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    894\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:688\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    681\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    682\u001b[0m         indexer,\n\u001b[1;32m    683\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    684\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    685\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 688\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    689\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    690\u001b[0m             indexer,\n\u001b[1;32m    691\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    692\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    693\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    694\u001b[0m             ),\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    697\u001b[0m     ]\n\u001b[1;32m    699\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    700\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:689\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    681\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    682\u001b[0m         indexer,\n\u001b[1;32m    683\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    684\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    685\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 689\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    697\u001b[0m     ]\n\u001b[1;32m    699\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    700\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/array_algos/take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#1732\n",
    "#767\n",
    "\n",
    "\n",
    "_year = 2023\n",
    "#dfFires = pd.read_csv(f\"Dataset/b{_year}.csv\")\n",
    "dfFires = pd.read_csv(f\"DatasetWTrees/PreviousVersions/{_year}_checklocality2.csv\")\n",
    "dfTreesDRP = pd.read_csv('TreesPortugueseTerritoryDropped.csv')\n",
    "\n",
    "num_chunks = 20\n",
    "\n",
    "# Split the DataFrame into smaller chunks\n",
    "chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "print(\"here\")\n",
    "\n",
    "# Apply the function to each chunk\n",
    "for i in range(num_chunks):\n",
    "    chunks[i]['scientificNames'] = chunks[i].apply(check_byCoord, axis=1)\n",
    "    empty_count = (chunks[i]['scientificNames'] == '').sum()\n",
    "    print(f'Empty count in chunk {i}: {empty_count}')\n",
    "    non_empty_count = (chunks[i]['scientificNames'] != '').sum()\n",
    "    print(f'Non empty count in chunk {i}: {non_empty_count}')\n",
    "\n",
    "    chunks[i].to_csv(f'DatasetWTrees/PreviousVersions/check_byCoord/{_year}_chunk_{i}.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "dfFires = pd.concat(chunks)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Locality\")\n",
    "empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "print(empty_count)\n",
    "\n",
    "non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "print(non_empty_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_year(_year):\n",
    "    dfFires = pd.read_csv(f\"Dataset/b{_year}.csv\")\n",
    "    dfTreesDRP = pd.read_csv('TreesPortugueseTerritoryDropped.csv')\n",
    "    print(len(dfFires))\n",
    "\n",
    "    num_chunks = 20\n",
    "\n",
    "    # Split the DataFrame into smaller chunks\n",
    "    chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "    # Apply the function to each chunk\n",
    "    for i in range(num_chunks):\n",
    "        chunks[i]['scientificNames'] = chunks[i].apply(check_locality, axis=1)\n",
    "        empty_count = (chunks[i]['scientificNames'] == '').sum()\n",
    "        print(f'Empty count in chunk {i}: {empty_count}')\n",
    "        non_empty_count = (chunks[i]['scientificNames'] != '').sum()\n",
    "        print(f'Non empty count in chunk {i}: {non_empty_count}')\n",
    "\n",
    "    dfFires = pd.concat(chunks)\n",
    "\n",
    "    print(\"Locality\")\n",
    "    empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "    print(empty_count)\n",
    "\n",
    "    non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "    print(non_empty_count)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool() as p:\n",
    "        p.map(process_year, [2023, 2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 130\n",
      "Non empty count in chunk: 1\n",
      "Empty count in chunk: 78\n",
      "Non empty count in chunk: 53\n",
      "Empty count in chunk: 93\n",
      "Non empty count in chunk: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 114\n",
      "Non empty count in chunk: 17\n",
      "Empty count in chunk: 107\n",
      "Non empty count in chunk: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 101\n",
      "Non empty count in chunk: 30\n",
      "Empty count in chunk: 99\n",
      "Non empty count in chunk: 32\n",
      "Empty count in chunk: 89\n",
      "Non empty count in chunk: 42\n",
      "Empty count in chunk: 90\n",
      "Non empty count in chunk: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 94\n",
      "Non empty count in chunk: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 83\n",
      "Non empty count in chunk: 47\n",
      "Empty count in chunk: 94\n",
      "Non empty count in chunk: 36\n",
      "Empty count in chunk: 121\n",
      "Non empty count in chunk: 9\n",
      "Empty count in chunk: 118\n",
      "Non empty count in chunk: 12\n",
      "Empty count in chunk: 69\n",
      "Non empty count in chunk: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 70\n",
      "Non empty count in chunk: 60\n",
      "Empty count in chunk: 72\n",
      "Non empty count in chunk: 58\n",
      "Empty count in chunk: 71\n",
      "Non empty count in chunk: 59\n",
      "Empty count in chunk: 121\n",
      "Non empty count in chunk: 9\n",
      "Empty count in chunk: 106\n",
      "Non empty count in chunk: 24\n",
      "Locality\n",
      "1920\n",
      "690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 91\n",
      "Non empty count in chunk: 40\n",
      "Empty count in chunk: 130\n",
      "Non empty count in chunk: 1\n",
      "Empty count in chunk: 94\n",
      "Non empty count in chunk: 37\n",
      "Empty count in chunk: 105\n",
      "Non empty count in chunk: 26\n",
      "Empty count in chunk: 75\n",
      "Non empty count in chunk: 56\n",
      "Empty count in chunk: 68\n",
      "Non empty count in chunk: 63\n",
      "Empty count in chunk: 71\n",
      "Non empty count in chunk: 60\n",
      "Empty count in chunk: 79\n",
      "Non empty count in chunk: 52\n",
      "Empty count in chunk: 80\n",
      "Non empty count in chunk: 51\n",
      "Empty count in chunk: 73\n",
      "Non empty count in chunk: 58\n",
      "Empty count in chunk: 79\n",
      "Non empty count in chunk: 51\n",
      "Empty count in chunk: 89\n",
      "Non empty count in chunk: 41\n",
      "Empty count in chunk: 118\n",
      "Non empty count in chunk: 12\n",
      "Empty count in chunk: 69\n",
      "Non empty count in chunk: 61\n",
      "Empty count in chunk: 121\n",
      "Non empty count in chunk: 9\n",
      "Empty count in chunk: 70\n",
      "Non empty count in chunk: 60\n",
      "Empty count in chunk: 69\n",
      "Non empty count in chunk: 61\n",
      "Empty count in chunk: 59\n",
      "Non empty count in chunk: 71\n",
      "Empty count in chunk: 80\n",
      "Non empty count in chunk: 50\n",
      "Empty count in chunk: 118\n",
      "Non empty count in chunk: 12\n",
      "Locality\n",
      "1738\n",
      "872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 195\n",
      "Non empty count in chunk: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 200\n",
      "Non empty count in chunk: 2\n",
      "Empty count in chunk: 105\n",
      "Non empty count in chunk: 97\n",
      "Empty count in chunk: 201\n",
      "Non empty count in chunk: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 135\n",
      "Non empty count in chunk: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 107\n",
      "Non empty count in chunk: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 158\n",
      "Non empty count in chunk: 44\n",
      "Empty count in chunk: 168\n",
      "Non empty count in chunk: 34\n",
      "Empty count in chunk: 165\n",
      "Non empty count in chunk: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 148\n",
      "Non empty count in chunk: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 154\n",
      "Non empty count in chunk: 48\n",
      "Empty count in chunk: 151\n",
      "Non empty count in chunk: 51\n",
      "Empty count in chunk: 162\n",
      "Non empty count in chunk: 40\n",
      "Empty count in chunk: 156\n",
      "Non empty count in chunk: 46\n",
      "Empty count in chunk: 157\n",
      "Non empty count in chunk: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 158\n",
      "Non empty count in chunk: 44\n",
      "Empty count in chunk: 148\n",
      "Non empty count in chunk: 54\n",
      "Empty count in chunk: 169\n",
      "Non empty count in chunk: 33\n",
      "Empty count in chunk: 176\n",
      "Non empty count in chunk: 26\n",
      "Empty count in chunk: 180\n",
      "Non empty count in chunk: 22\n",
      "Locality\n",
      "3193\n",
      "847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 96\n",
      "Non empty count in chunk: 106\n",
      "Empty count in chunk: 131\n",
      "Non empty count in chunk: 71\n",
      "Empty count in chunk: 201\n",
      "Non empty count in chunk: 1\n",
      "Empty count in chunk: 200\n",
      "Non empty count in chunk: 2\n",
      "Empty count in chunk: 195\n",
      "Non empty count in chunk: 7\n",
      "Empty count in chunk: 153\n",
      "Non empty count in chunk: 49\n",
      "Empty count in chunk: 143\n",
      "Non empty count in chunk: 59\n",
      "Empty count in chunk: 107\n",
      "Non empty count in chunk: 95\n",
      "Empty count in chunk: 133\n",
      "Non empty count in chunk: 69\n",
      "Empty count in chunk: 152\n",
      "Non empty count in chunk: 50\n",
      "Empty count in chunk: 134\n",
      "Non empty count in chunk: 68\n",
      "Empty count in chunk: 141\n",
      "Non empty count in chunk: 61\n",
      "Empty count in chunk: 136\n",
      "Non empty count in chunk: 66\n",
      "Empty count in chunk: 133\n",
      "Non empty count in chunk: 69\n",
      "Empty count in chunk: 140\n",
      "Non empty count in chunk: 62\n",
      "Empty count in chunk: 127\n",
      "Non empty count in chunk: 75\n",
      "Empty count in chunk: 123\n",
      "Non empty count in chunk: 79\n",
      "Empty count in chunk: 170\n",
      "Non empty count in chunk: 32\n",
      "Empty count in chunk: 147\n",
      "Non empty count in chunk: 55\n",
      "Empty count in chunk: 168\n",
      "Non empty count in chunk: 34\n",
      "Locality\n",
      "2930\n",
      "1110\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "dfTreesDRP = pd.read_csv('TreesPortugueseTerritoryDropped.csv')\n",
    "\n",
    "def process_chunkv1(chunk):\n",
    "    chunk['scientificNames'] = chunk.apply(check_locality, axis=1)\n",
    "    empty_count = (chunk['scientificNames'] == '').sum()\n",
    "    print(f'Empty count in chunk: {empty_count}')\n",
    "    non_empty_count = (chunk['scientificNames'] != '').sum()\n",
    "    print(f'Non empty count in chunk: {non_empty_count}')\n",
    "    return chunk\n",
    "\n",
    "def process_chunkv2(chunk):\n",
    "    chunk['scientificNames'] = chunk.apply(check_locality2, axis=1)\n",
    "    empty_count = (chunk['scientificNames'] == '').sum()\n",
    "    print(f'Empty count in chunk: {empty_count}')\n",
    "    non_empty_count = (chunk['scientificNames'] != '').sum()\n",
    "    print(f'Non empty count in chunk: {non_empty_count}')\n",
    "    return chunk\n",
    "\n",
    "for _year in range(2021, 2023):\n",
    "\n",
    "    if ((_year != 2022) or (_year != 2021)):\n",
    "\n",
    "        dfFires = pd.read_csv(f\"Dataset/b{_year}.csv\")\n",
    "        num_chunks = 20\n",
    "\n",
    "        # Split the DataFrame into smaller chunks\n",
    "        chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "        # Create a ProcessPoolExecutor\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:\n",
    "            # Use the executor to map the function to the chunks\n",
    "            chunks = list(executor.map(process_chunkv1, chunks))\n",
    "\n",
    "        # Concatenate the chunks back into a single DataFrame\n",
    "        dfFires = pd.concat(chunks)\n",
    "\n",
    "        dfFires.to_csv(f'DatasetWTrees/PreviousVersions/{_year}_checklocality.csv', index=False)\n",
    "\n",
    "        print(\"Locality\")\n",
    "        empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "        print(empty_count)\n",
    "\n",
    "        non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "        print(non_empty_count)\n",
    "\n",
    "    dfFires = pd.read_csv(f\"DatasetWTrees/PreviousVersions/{_year}_checklocality.csv\")\n",
    "\n",
    "    num_chunks = 20\n",
    "\n",
    "    # Split the DataFrame into smaller chunks\n",
    "    chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:\n",
    "        # Use the executor to map the function to the chunks\n",
    "        chunks = list(executor.map(process_chunkv2, chunks))\n",
    "\n",
    "    dfFires = pd.concat(chunks)\n",
    "\n",
    "    dfFires.to_csv(f'DatasetWTrees/PreviousVersions/{_year}_checklocality2.csv', index=False)\n",
    "\n",
    "    print(\"Locality\")\n",
    "    empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "    print(empty_count)\n",
    "\n",
    "    non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "    print(non_empty_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 751\n",
      "Non empty count in chunk: 549\n",
      "Empty count in chunk: 1135\n",
      "Non empty count in chunk: 164\n",
      "Empty count in chunk: 1059\n",
      "Non empty count in chunk: 240\n",
      "Empty count in chunk: 889\n",
      "Non empty count in chunk: 411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1070\n",
      "Non empty count in chunk: 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1156\n",
      "Non empty count in chunk: 143\n",
      "Empty count in chunk: 1167\n",
      "Non empty count in chunk: 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1191\n",
      "Non empty count in chunk: 108\n",
      "Empty count in chunk: 1169\n",
      "Non empty count in chunk: 130\n",
      "Empty count in chunk: 1074\n",
      "Non empty count in chunk: 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1105\n",
      "Non empty count in chunk: 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1087\n",
      "Non empty count in chunk: 212\n",
      "Empty count in chunk: 1061\n",
      "Non empty count in chunk: 238\n",
      "Empty count in chunk: 1085\n",
      "Non empty count in chunk: 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 802\n",
      "Non empty count in chunk: 497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 737\n",
      "Non empty count in chunk: 562\n",
      "Empty count in chunk: 859\n",
      "Non empty count in chunk: 440\n",
      "Empty count in chunk: 1096\n",
      "Non empty count in chunk: 203\n",
      "Empty count in chunk: 1170\n",
      "Non empty count in chunk: 129\n",
      "Empty count in chunk: 1218\n",
      "Non empty count in chunk: 81\n",
      "Locality\n",
      "20881\n",
      "5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1024\n",
      "Non empty count in chunk: 275\n",
      "Empty count in chunk: 961\n",
      "Non empty count in chunk: 338\n",
      "Empty count in chunk: 862\n",
      "Non empty count in chunk: 438\n",
      "Empty count in chunk: 1089\n",
      "Non empty count in chunk: 210\n",
      "Empty count in chunk: 741\n",
      "Non empty count in chunk: 559\n",
      "Empty count in chunk: 1112\n",
      "Non empty count in chunk: 187\n",
      "Empty count in chunk: 1120\n",
      "Non empty count in chunk: 179\n",
      "Empty count in chunk: 1132\n",
      "Non empty count in chunk: 167\n",
      "Empty count in chunk: 931\n",
      "Non empty count in chunk: 368\n",
      "Empty count in chunk: 1128\n",
      "Non empty count in chunk: 171\n",
      "Empty count in chunk: 974\n",
      "Non empty count in chunk: 325\n",
      "Empty count in chunk: 1021\n",
      "Non empty count in chunk: 278\n",
      "Empty count in chunk: 979\n",
      "Non empty count in chunk: 320\n",
      "Empty count in chunk: 1016\n",
      "Non empty count in chunk: 283\n",
      "Empty count in chunk: 745\n",
      "Non empty count in chunk: 554\n",
      "Empty count in chunk: 1077\n",
      "Non empty count in chunk: 222\n",
      "Empty count in chunk: 701\n",
      "Non empty count in chunk: 598\n",
      "Empty count in chunk: 799\n",
      "Non empty count in chunk: 500\n",
      "Empty count in chunk: 1162\n",
      "Non empty count in chunk: 137\n",
      "Empty count in chunk: 1210\n",
      "Non empty count in chunk: 89\n",
      "Locality\n",
      "19784\n",
      "6198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 820\n",
      "Non empty count in chunk: 463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 874\n",
      "Non empty count in chunk: 409\n",
      "Empty count in chunk: 1096\n",
      "Non empty count in chunk: 187\n",
      "Empty count in chunk: 1162\n",
      "Non empty count in chunk: 121\n",
      "Empty count in chunk: 958\n",
      "Non empty count in chunk: 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1141\n",
      "Non empty count in chunk: 142\n",
      "Empty count in chunk: 1015\n",
      "Non empty count in chunk: 268\n",
      "Empty count in chunk: 1184\n",
      "Non empty count in chunk: 99\n",
      "Empty count in chunk: 1208\n",
      "Non empty count in chunk: 75\n",
      "Empty count in chunk: 1242\n",
      "Non empty count in chunk: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1072\n",
      "Non empty count in chunk: 210\n",
      "Empty count in chunk: 1059\n",
      "Non empty count in chunk: 223\n",
      "Empty count in chunk: 1084\n",
      "Non empty count in chunk: 198\n",
      "Empty count in chunk: 907\n",
      "Non empty count in chunk: 375\n",
      "Empty count in chunk: 936\n",
      "Non empty count in chunk: 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 798\n",
      "Non empty count in chunk: 484\n",
      "Empty count in chunk: 848\n",
      "Non empty count in chunk: 434\n",
      "Empty count in chunk: 773\n",
      "Non empty count in chunk: 509\n",
      "Empty count in chunk: 1182\n",
      "Non empty count in chunk: 100\n",
      "Empty count in chunk: 1225\n",
      "Non empty count in chunk: 57\n",
      "Locality\n",
      "20584\n",
      "5066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 851\n",
      "Non empty count in chunk: 432\n",
      "Empty count in chunk: 998\n",
      "Non empty count in chunk: 285\n",
      "Empty count in chunk: 801\n",
      "Non empty count in chunk: 482\n",
      "Empty count in chunk: 791\n",
      "Non empty count in chunk: 492\n",
      "Empty count in chunk: 1075\n",
      "Non empty count in chunk: 208\n",
      "Empty count in chunk: 1141\n",
      "Non empty count in chunk: 142\n",
      "Empty count in chunk: 884\n",
      "Non empty count in chunk: 399\n",
      "Empty count in chunk: 1182\n",
      "Non empty count in chunk: 101\n",
      "Empty count in chunk: 1242\n",
      "Non empty count in chunk: 41\n",
      "Empty count in chunk: 1208\n",
      "Non empty count in chunk: 75\n",
      "Empty count in chunk: 988\n",
      "Non empty count in chunk: 294\n",
      "Empty count in chunk: 932\n",
      "Non empty count in chunk: 350\n",
      "Empty count in chunk: 800\n",
      "Non empty count in chunk: 482\n",
      "Empty count in chunk: 975\n",
      "Non empty count in chunk: 307\n",
      "Empty count in chunk: 885\n",
      "Non empty count in chunk: 397\n",
      "Empty count in chunk: 691\n",
      "Non empty count in chunk: 591\n",
      "Empty count in chunk: 1177\n",
      "Non empty count in chunk: 105\n",
      "Empty count in chunk: 689\n",
      "Non empty count in chunk: 593\n",
      "Empty count in chunk: 805\n",
      "Non empty count in chunk: 477\n",
      "Empty count in chunk: 1223\n",
      "Non empty count in chunk: 59\n",
      "Locality\n",
      "19338\n",
      "6312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 885\n",
      "Non empty count in chunk: 372\n",
      "Empty count in chunk: 780\n",
      "Non empty count in chunk: 477\n",
      "Empty count in chunk: 1125\n",
      "Non empty count in chunk: 132\n",
      "Empty count in chunk: 1115\n",
      "Non empty count in chunk: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 900\n",
      "Non empty count in chunk: 357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 843\n",
      "Non empty count in chunk: 414\n",
      "Empty count in chunk: 1222\n",
      "Non empty count in chunk: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1076\n",
      "Non empty count in chunk: 181\n",
      "Empty count in chunk: 924\n",
      "Non empty count in chunk: 333\n",
      "Empty count in chunk: 1004\n",
      "Non empty count in chunk: 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1160\n",
      "Non empty count in chunk: 97\n",
      "Empty count in chunk: 879\n",
      "Non empty count in chunk: 378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1135\n",
      "Non empty count in chunk: 122\n",
      "Empty count in chunk: 1219\n",
      "Non empty count in chunk: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1067\n",
      "Non empty count in chunk: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 841\n",
      "Non empty count in chunk: 416\n",
      "Empty count in chunk: 756\n",
      "Non empty count in chunk: 501\n",
      "Empty count in chunk: 726\n",
      "Non empty count in chunk: 531\n",
      "Empty count in chunk: 871\n",
      "Non empty count in chunk: 386\n",
      "Empty count in chunk: 1136\n",
      "Non empty count in chunk: 120\n",
      "Locality\n",
      "19664\n",
      "5475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 871\n",
      "Non empty count in chunk: 386\n",
      "Empty count in chunk: 722\n",
      "Non empty count in chunk: 535\n",
      "Empty count in chunk: 1018\n",
      "Non empty count in chunk: 239\n",
      "Empty count in chunk: 1032\n",
      "Non empty count in chunk: 225\n",
      "Empty count in chunk: 767\n",
      "Non empty count in chunk: 490\n",
      "Empty count in chunk: 718\n",
      "Non empty count in chunk: 539\n",
      "Empty count in chunk: 826\n",
      "Non empty count in chunk: 431\n",
      "Empty count in chunk: 1222\n",
      "Non empty count in chunk: 35\n",
      "Empty count in chunk: 955\n",
      "Non empty count in chunk: 302\n",
      "Empty count in chunk: 744\n",
      "Non empty count in chunk: 513\n",
      "Empty count in chunk: 790\n",
      "Non empty count in chunk: 467\n",
      "Empty count in chunk: 1160\n",
      "Non empty count in chunk: 97\n",
      "Empty count in chunk: 1134\n",
      "Non empty count in chunk: 123\n",
      "Empty count in chunk: 1219\n",
      "Non empty count in chunk: 38\n",
      "Empty count in chunk: 986\n",
      "Non empty count in chunk: 271\n",
      "Empty count in chunk: 738\n",
      "Non empty count in chunk: 519\n",
      "Empty count in chunk: 715\n",
      "Non empty count in chunk: 542\n",
      "Empty count in chunk: 813\n",
      "Non empty count in chunk: 444\n",
      "Empty count in chunk: 691\n",
      "Non empty count in chunk: 566\n",
      "Empty count in chunk: 1122\n",
      "Non empty count in chunk: 134\n",
      "Locality\n",
      "18243\n",
      "6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 686\n",
      "Non empty count in chunk: 374\n",
      "Empty count in chunk: 934\n",
      "Non empty count in chunk: 126\n",
      "Empty count in chunk: 648\n",
      "Non empty count in chunk: 412\n",
      "Empty count in chunk: 1039\n",
      "Non empty count in chunk: 21\n",
      "Empty count in chunk: 720\n",
      "Non empty count in chunk: 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 972\n",
      "Non empty count in chunk: 88\n",
      "Empty count in chunk: 786\n",
      "Non empty count in chunk: 274\n",
      "Empty count in chunk: 764\n",
      "Non empty count in chunk: 296\n",
      "Empty count in chunk: 796\n",
      "Non empty count in chunk: 264\n",
      "Empty count in chunk: 824\n",
      "Non empty count in chunk: 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 799\n",
      "Non empty count in chunk: 260\n",
      "Empty count in chunk: 801\n",
      "Non empty count in chunk: 258\n",
      "Empty count in chunk: 1044\n",
      "Non empty count in chunk: 15\n",
      "Empty count in chunk: 1039\n",
      "Non empty count in chunk: 20\n",
      "Empty count in chunk: 936\n",
      "Non empty count in chunk: 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 488\n",
      "Non empty count in chunk: 571\n",
      "Empty count in chunk: 526\n",
      "Non empty count in chunk: 533\n",
      "Empty count in chunk: 992\n",
      "Non empty count in chunk: 67\n",
      "Empty count in chunk: 626\n",
      "Non empty count in chunk: 433\n",
      "Empty count in chunk: 1029\n",
      "Non empty count in chunk: 30\n",
      "Locality\n",
      "16449\n",
      "4740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 625\n",
      "Non empty count in chunk: 435\n",
      "Empty count in chunk: 667\n",
      "Non empty count in chunk: 393\n",
      "Empty count in chunk: 925\n",
      "Non empty count in chunk: 135\n",
      "Empty count in chunk: 673\n",
      "Non empty count in chunk: 387\n",
      "Empty count in chunk: 1039\n",
      "Non empty count in chunk: 21\n",
      "Empty count in chunk: 686\n",
      "Non empty count in chunk: 374\n",
      "Empty count in chunk: 663\n",
      "Non empty count in chunk: 397\n",
      "Empty count in chunk: 897\n",
      "Non empty count in chunk: 163\n",
      "Empty count in chunk: 692\n",
      "Non empty count in chunk: 368\n",
      "Empty count in chunk: 704\n",
      "Non empty count in chunk: 355\n",
      "Empty count in chunk: 801\n",
      "Non empty count in chunk: 258\n",
      "Empty count in chunk: 748\n",
      "Non empty count in chunk: 311\n",
      "Empty count in chunk: 936\n",
      "Non empty count in chunk: 123\n",
      "Empty count in chunk: 1039\n",
      "Non empty count in chunk: 20\n",
      "Empty count in chunk: 1044\n",
      "Non empty count in chunk: 15\n",
      "Empty count in chunk: 524\n",
      "Non empty count in chunk: 535\n",
      "Empty count in chunk: 484\n",
      "Non empty count in chunk: 575\n",
      "Empty count in chunk: 941\n",
      "Non empty count in chunk: 118\n",
      "Empty count in chunk: 1029\n",
      "Non empty count in chunk: 30\n",
      "Empty count in chunk: 501\n",
      "Non empty count in chunk: 558\n",
      "Locality\n",
      "15618\n",
      "5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1046\n",
      "Non empty count in chunk: 683\n",
      "Empty count in chunk: 1074\n",
      "Non empty count in chunk: 655\n",
      "Empty count in chunk: 1661\n",
      "Non empty count in chunk: 68\n",
      "Empty count in chunk: 1191\n",
      "Non empty count in chunk: 538\n",
      "Empty count in chunk: 1171\n",
      "Non empty count in chunk: 558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1698\n",
      "Non empty count in chunk: 31\n",
      "Empty count in chunk: 1675\n",
      "Non empty count in chunk: 54\n",
      "Empty count in chunk: 1413\n",
      "Non empty count in chunk: 316\n",
      "Empty count in chunk: 1482\n",
      "Non empty count in chunk: 247\n",
      "Empty count in chunk: 1305\n",
      "Non empty count in chunk: 424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1353\n",
      "Non empty count in chunk: 376\n",
      "Empty count in chunk: 1335\n",
      "Non empty count in chunk: 394\n",
      "Empty count in chunk: 1301\n",
      "Non empty count in chunk: 428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1693\n",
      "Non empty count in chunk: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1682\n",
      "Non empty count in chunk: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1009\n",
      "Non empty count in chunk: 720\n",
      "Empty count in chunk: 1600\n",
      "Non empty count in chunk: 129\n",
      "Empty count in chunk: 983\n",
      "Non empty count in chunk: 746\n",
      "Empty count in chunk: 1609\n",
      "Non empty count in chunk: 119\n",
      "Empty count in chunk: 1642\n",
      "Non empty count in chunk: 86\n",
      "Locality\n",
      "27923\n",
      "6655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 1025\n",
      "Non empty count in chunk: 704\n",
      "Empty count in chunk: 1054\n",
      "Non empty count in chunk: 675\n",
      "Empty count in chunk: 1163\n",
      "Non empty count in chunk: 566\n",
      "Empty count in chunk: 1124\n",
      "Non empty count in chunk: 605\n",
      "Empty count in chunk: 1661\n",
      "Non empty count in chunk: 68\n",
      "Empty count in chunk: 1698\n",
      "Non empty count in chunk: 31\n",
      "Empty count in chunk: 1221\n",
      "Non empty count in chunk: 508\n",
      "Empty count in chunk: 1098\n",
      "Non empty count in chunk: 631\n",
      "Empty count in chunk: 1168\n",
      "Non empty count in chunk: 561\n",
      "Empty count in chunk: 1595\n",
      "Non empty count in chunk: 134\n",
      "Empty count in chunk: 1353\n",
      "Non empty count in chunk: 376\n",
      "Empty count in chunk: 1106\n",
      "Non empty count in chunk: 623\n",
      "Empty count in chunk: 1122\n",
      "Non empty count in chunk: 607\n",
      "Empty count in chunk: 1693\n",
      "Non empty count in chunk: 36\n",
      "Empty count in chunk: 1682\n",
      "Non empty count in chunk: 47\n",
      "Empty count in chunk: 1600\n",
      "Non empty count in chunk: 129\n",
      "Empty count in chunk: 978\n",
      "Non empty count in chunk: 751\n",
      "Empty count in chunk: 1517\n",
      "Non empty count in chunk: 211\n",
      "Empty count in chunk: 934\n",
      "Non empty count in chunk: 795\n",
      "Empty count in chunk: 1641\n",
      "Non empty count in chunk: 87\n",
      "Locality\n",
      "26433\n",
      "8145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 517\n",
      "Non empty count in chunk: 442\n",
      "Empty count in chunk: 575\n",
      "Non empty count in chunk: 384\n",
      "Empty count in chunk: 700\n",
      "Non empty count in chunk: 259\n",
      "Empty count in chunk: 664\n",
      "Non empty count in chunk: 295\n",
      "Empty count in chunk: 862\n",
      "Non empty count in chunk: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 922\n",
      "Non empty count in chunk: 37\n",
      "Empty count in chunk: 807\n",
      "Non empty count in chunk: 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 761\n",
      "Non empty count in chunk: 198\n",
      "Empty count in chunk: 725Non empty count in chunk: 234\n",
      "\n",
      "Empty count in chunk: 764\n",
      "Non empty count in chunk: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 725\n",
      "Non empty count in chunk: 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 904\n",
      "Non empty count in chunk: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 738\n",
      "Non empty count in chunk: 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 930\n",
      "Non empty count in chunk: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 928\n",
      "Non empty count in chunk: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 658\n",
      "Non empty count in chunk: 300\n",
      "Empty count in chunk: 462\n",
      "Non empty count in chunk: 496\n",
      "Empty count in chunk: 542\n",
      "Non empty count in chunk: 416\n",
      "Empty count in chunk: 847\n",
      "Non empty count in chunk: 111\n",
      "Empty count in chunk: 920\n",
      "Non empty count in chunk: 38\n",
      "Locality\n",
      "14951\n",
      "4224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 517\n",
      "Non empty count in chunk: 442\n",
      "Empty count in chunk: 563\n",
      "Non empty count in chunk: 396\n",
      "Empty count in chunk: 685\n",
      "Non empty count in chunk: 274\n",
      "Empty count in chunk: 862\n",
      "Non empty count in chunk: 97\n",
      "Empty count in chunk: 645\n",
      "Non empty count in chunk: 314\n",
      "Empty count in chunk: 687\n",
      "Non empty count in chunk: 272\n",
      "Empty count in chunk: 659\n",
      "Non empty count in chunk: 300\n",
      "Empty count in chunk: 646\n",
      "Non empty count in chunk: 313\n",
      "Empty count in chunk: 867\n",
      "Non empty count in chunk: 92\n",
      "Empty count in chunk: 606\n",
      "Non empty count in chunk: 353\n",
      "Empty count in chunk: 707\n",
      "Non empty count in chunk: 252\n",
      "Empty count in chunk: 623\n",
      "Non empty count in chunk: 336\n",
      "Empty count in chunk: 904\n",
      "Non empty count in chunk: 55\n",
      "Empty count in chunk: 930\n",
      "Non empty count in chunk: 29\n",
      "Empty count in chunk: 928\n",
      "Non empty count in chunk: 31\n",
      "Empty count in chunk: 654\n",
      "Non empty count in chunk: 304\n",
      "Empty count in chunk: 918\n",
      "Non empty count in chunk: 40\n",
      "Empty count in chunk: 448\n",
      "Non empty count in chunk: 510\n",
      "Empty count in chunk: 694\n",
      "Non empty count in chunk: 264\n",
      "Empty count in chunk: 443\n",
      "Non empty count in chunk: 515\n",
      "Locality\n",
      "13986\n",
      "5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 478\n",
      "Non empty count in chunk: 303\n",
      "Empty count in chunk: 736\n",
      "Non empty count in chunk: 45\n",
      "Empty count in chunk: 764\n",
      "Non empty count in chunk: 17\n",
      "Empty count in chunk: 505\n",
      "Non empty count in chunk: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 505\n",
      "Non empty count in chunk: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 625\n",
      "Non empty count in chunk: 156\n",
      "Empty count in chunk: 588\n",
      "Non empty count in chunk: 193\n",
      "Empty count in chunk: 618\n",
      "Non empty count in chunk: 163\n",
      "Empty count in chunk: 602\n",
      "Non empty count in chunk: 179\n",
      "Empty count in chunk: 583\n",
      "Non empty count in chunk: 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 664\n",
      "Non empty count in chunk: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 386\n",
      "Non empty count in chunk: 395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 758\n",
      "Non empty count in chunk: 23\n",
      "Empty count in chunk: 758\n",
      "Non empty count in chunk: 23\n",
      "Empty count in chunk: 629\n",
      "Non empty count in chunk: 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 432\n",
      "Non empty count in chunk: 348\n",
      "Empty count in chunk: 702\n",
      "Non empty count in chunk: 78\n",
      "Empty count in chunk: 761\n",
      "Non empty count in chunk: 19\n",
      "Empty count in chunk: 484\n",
      "Non empty count in chunk: 296\n",
      "Empty count in chunk: 744\n",
      "Non empty count in chunk: 36\n",
      "Locality\n",
      "12322\n",
      "3293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 736\n",
      "Non empty count in chunk: 45\n",
      "Empty count in chunk: 471\n",
      "Non empty count in chunk: 310\n",
      "Empty count in chunk: 471\n",
      "Non empty count in chunk: 310\n",
      "Empty count in chunk: 494\n",
      "Non empty count in chunk: 287\n",
      "Empty count in chunk: 764\n",
      "Non empty count in chunk: 17\n",
      "Empty count in chunk: 531\n",
      "Non empty count in chunk: 250\n",
      "Empty count in chunk: 551\n",
      "Non empty count in chunk: 230\n",
      "Empty count in chunk: 535\n",
      "Non empty count in chunk: 246\n",
      "Empty count in chunk: 546\n",
      "Non empty count in chunk: 235\n",
      "Empty count in chunk: 512\n",
      "Non empty count in chunk: 269\n",
      "Empty count in chunk: 664\n",
      "Non empty count in chunk: 117\n",
      "Empty count in chunk: 758\n",
      "Non empty count in chunk: 23\n",
      "Empty count in chunk: 629\n",
      "Non empty count in chunk: 152\n",
      "Empty count in chunk: 758\n",
      "Non empty count in chunk: 23\n",
      "Empty count in chunk: 382\n",
      "Non empty count in chunk: 399\n",
      "Empty count in chunk: 431\n",
      "Non empty count in chunk: 349\n",
      "Empty count in chunk: 761\n",
      "Non empty count in chunk: 19\n",
      "Empty count in chunk: 590\n",
      "Non empty count in chunk: 190\n",
      "Empty count in chunk: 744\n",
      "Non empty count in chunk: 36\n",
      "Empty count in chunk: 390\n",
      "Non empty count in chunk: 390\n",
      "Locality\n",
      "11718\n",
      "3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 420\n",
      "Non empty count in chunk: 76\n",
      "Empty count in chunk: 314\n",
      "Non empty count in chunk: 182\n",
      "Empty count in chunk: 266\n",
      "Non empty count in chunk: 230\n",
      "Empty count in chunk: 489\n",
      "Non empty count in chunk: 7\n",
      "Empty count in chunk: 276\n",
      "Non empty count in chunk: 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 453\n",
      "Non empty count in chunk: 42\n",
      "Empty count in chunk: 401\n",
      "Non empty count in chunk: 94\n",
      "Empty count in chunk: 389\n",
      "Non empty count in chunk: 106\n",
      "Empty count in chunk: 396\n",
      "Non empty count in chunk: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 386\n",
      "Non empty count in chunk: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 216\n",
      "Non empty count in chunk: 279\n",
      "Empty count in chunk: 487\n",
      "Non empty count in chunk: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 409\n",
      "Non empty count in chunk: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 264\n",
      "Non empty count in chunk: 231\n",
      "Empty count in chunk: 439\n",
      "Non empty count in chunk: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 461\n",
      "Non empty count in chunk: 34\n",
      "Empty count in chunk: 374\n",
      "Non empty count in chunk: 121\n",
      "Empty count in chunk: 211\n",
      "Non empty count in chunk: 284\n",
      "Empty count in chunk: 475\n",
      "Non empty count in chunk: 20\n",
      "Empty count in chunk: 484\n",
      "Non empty count in chunk: 11\n",
      "Locality\n",
      "7610\n",
      "2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 263\n",
      "Non empty count in chunk: 233\n",
      "Empty count in chunk: 314\n",
      "Non empty count in chunk: 182\n",
      "Empty count in chunk: 263\n",
      "Non empty count in chunk: 233\n",
      "Empty count in chunk: 414\n",
      "Non empty count in chunk: 82\n",
      "Empty count in chunk: 489\n",
      "Non empty count in chunk: 7\n",
      "Empty count in chunk: 347\n",
      "Non empty count in chunk: 148\n",
      "Empty count in chunk: 433\n",
      "Non empty count in chunk: 62\n",
      "Empty count in chunk: 350\n",
      "Non empty count in chunk: 145\n",
      "Empty count in chunk: 359\n",
      "Non empty count in chunk: 136\n",
      "Empty count in chunk: 331\n",
      "Non empty count in chunk: 164\n",
      "Empty count in chunk: 380\n",
      "Non empty count in chunk: 115\n",
      "Empty count in chunk: 439\n",
      "Non empty count in chunk: 56\n",
      "Empty count in chunk: 215\n",
      "Non empty count in chunk: 280\n",
      "Empty count in chunk: 487\n",
      "Non empty count in chunk: 8\n",
      "Empty count in chunk: 262\n",
      "Non empty count in chunk: 233\n",
      "Empty count in chunk: 208\n",
      "Non empty count in chunk: 287\n",
      "Empty count in chunk: 475\n",
      "Non empty count in chunk: 20\n",
      "Empty count in chunk: 417\n",
      "Non empty count in chunk: 78\n",
      "Empty count in chunk: 250\n",
      "Non empty count in chunk: 245\n",
      "Empty count in chunk: 482\n",
      "Non empty count in chunk: 13\n",
      "Locality\n",
      "7178\n",
      "2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 497\n",
      "Non empty count in chunk: 373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 790\n",
      "Non empty count in chunk: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 495\n",
      "Non empty count in chunk: 375\n",
      "Empty count in chunk: 750\n",
      "Non empty count in chunk: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 845\n",
      "Non empty count in chunk: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 707\n",
      "Non empty count in chunk: 163\n",
      "Empty count in chunk: 582\n",
      "Non empty count in chunk: 288\n",
      "Empty count in chunk: 586\n",
      "Non empty count in chunk: 284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 631\n",
      "Non empty count in chunk: 239\n",
      "Empty count in chunk: 666\n",
      "Non empty count in chunk: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 661\n",
      "Non empty count in chunk: 209\n",
      "Empty count in chunk: 648\n",
      "Non empty count in chunk: 222\n",
      "Empty count in chunk: 735\n",
      "Non empty count in chunk: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 851\n",
      "Non empty count in chunk: 19\n",
      "Empty count in chunk: 846\n",
      "Non empty count in chunk: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 808\n",
      "Non empty count in chunk: 62\n",
      "Empty count in chunk: 429\n",
      "Non empty count in chunk: 441\n",
      "Empty count in chunk: 564\n",
      "Non empty count in chunk: 306\n",
      "Empty count in chunk: 862\n",
      "Non empty count in chunk: 8\n",
      "Empty count in chunk: 839\n",
      "Non empty count in chunk: 30\n",
      "Locality\n",
      "13792\n",
      "3607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 486\n",
      "Non empty count in chunk: 384\n",
      "Empty count in chunk: 488\n",
      "Non empty count in chunk: 382\n",
      "Empty count in chunk: 746\n",
      "Non empty count in chunk: 124\n",
      "Empty count in chunk: 752\n",
      "Non empty count in chunk: 118\n",
      "Empty count in chunk: 845\n",
      "Non empty count in chunk: 25\n",
      "Empty count in chunk: 642\n",
      "Non empty count in chunk: 228\n",
      "Empty count in chunk: 512\n",
      "Non empty count in chunk: 358\n",
      "Empty count in chunk: 569\n",
      "Non empty count in chunk: 301\n",
      "Empty count in chunk: 536\n",
      "Non empty count in chunk: 334\n",
      "Empty count in chunk: 499\n",
      "Non empty count in chunk: 371\n",
      "Empty count in chunk: 559\n",
      "Non empty count in chunk: 311\n",
      "Empty count in chunk: 579\n",
      "Non empty count in chunk: 291\n",
      "Empty count in chunk: 707\n",
      "Non empty count in chunk: 163\n",
      "Empty count in chunk: 851\n",
      "Non empty count in chunk: 19\n",
      "Empty count in chunk: 846\n",
      "Non empty count in chunk: 24\n",
      "Empty count in chunk: 726\n",
      "Non empty count in chunk: 144\n",
      "Empty count in chunk: 561\n",
      "Non empty count in chunk: 309\n",
      "Empty count in chunk: 862\n",
      "Non empty count in chunk: 8\n",
      "Empty count in chunk: 385\n",
      "Non empty count in chunk: 485\n",
      "Empty count in chunk: 837\n",
      "Non empty count in chunk: 32\n",
      "Locality\n",
      "12988\n",
      "4411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 610\n",
      "Non empty count in chunk: 112\n",
      "Empty count in chunk: 565\n",
      "Non empty count in chunk: 157\n",
      "Empty count in chunk: 589\n",
      "Non empty count in chunk: 133\n",
      "Empty count in chunk: 589\n",
      "Non empty count in chunk: 133\n",
      "Empty count in chunk: 556\n",
      "Non empty count in chunk: 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 593\n",
      "Non empty count in chunk: 129\n",
      "Empty count in chunk: 602\n",
      "Non empty count in chunk: 120\n",
      "Empty count in chunk: 591\n",
      "Non empty count in chunk: 131\n",
      "Empty count in chunk: 577\n",
      "Non empty count in chunk: 145\n",
      "Empty count in chunk: 604\n",
      "Non empty count in chunk: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 580\n",
      "Non empty count in chunk: 141\n",
      "Empty count in chunk: 587\n",
      "Non empty count in chunk: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 593\n",
      "Non empty count in chunk: 128\n",
      "Empty count in chunk: 572\n",
      "Non empty count in chunk: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 575\n",
      "Non empty count in chunk: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 577\n",
      "Non empty count in chunk: 144\n",
      "Empty count in chunk: 573\n",
      "Non empty count in chunk: 148\n",
      "Empty count in chunk: 568\n",
      "Non empty count in chunk: 153\n",
      "Empty count in chunk: 556\n",
      "Non empty count in chunk: 165\n",
      "Empty count in chunk: 554\n",
      "Non empty count in chunk: 167\n",
      "Locality\n",
      "11611\n",
      "2819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 567\n",
      "Non empty count in chunk: 155\n",
      "Empty count in chunk: 551\n",
      "Non empty count in chunk: 171\n",
      "Empty count in chunk: 526\n",
      "Non empty count in chunk: 196\n",
      "Empty count in chunk: 550\n",
      "Non empty count in chunk: 172\n",
      "Empty count in chunk: 523\n",
      "Non empty count in chunk: 199\n",
      "Empty count in chunk: 552\n",
      "Non empty count in chunk: 170\n",
      "Empty count in chunk: 537\n",
      "Non empty count in chunk: 185\n",
      "Empty count in chunk: 557\n",
      "Non empty count in chunk: 165\n",
      "Empty count in chunk: 556\n",
      "Non empty count in chunk: 166\n",
      "Empty count in chunk: 564\n",
      "Non empty count in chunk: 158\n",
      "Empty count in chunk: 538\n",
      "Non empty count in chunk: 183\n",
      "Empty count in chunk: 554\n",
      "Non empty count in chunk: 167\n",
      "Empty count in chunk: 551\n",
      "Non empty count in chunk: 170\n",
      "Empty count in chunk: 534\n",
      "Non empty count in chunk: 187\n",
      "Empty count in chunk: 539\n",
      "Non empty count in chunk: 182\n",
      "Empty count in chunk: 535\n",
      "Non empty count in chunk: 186\n",
      "Empty count in chunk: 533\n",
      "Non empty count in chunk: 188\n",
      "Empty count in chunk: 492\n",
      "Non empty count in chunk: 229\n",
      "Empty count in chunk: 515\n",
      "Non empty count in chunk: 206\n",
      "Empty count in chunk: 526\n",
      "Non empty count in chunk: 195\n",
      "Locality\n",
      "10800\n",
      "3630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 641\n",
      "Non empty count in chunk: 105\n",
      "Empty count in chunk: 631\n",
      "Non empty count in chunk: 115\n",
      "Empty count in chunk: 666\n",
      "Non empty count in chunk: 80\n",
      "Empty count in chunk: 623\n",
      "Non empty count in chunk: 123\n",
      "Empty count in chunk: 630\n",
      "Non empty count in chunk: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 616\n",
      "Non empty count in chunk: 130\n",
      "Empty count in chunk: 607\n",
      "Non empty count in chunk: 139\n",
      "Empty count in chunk: 632\n",
      "Non empty count in chunk: 114\n",
      "Empty count in chunk: 599\n",
      "Non empty count in chunk: 147\n",
      "Empty count in chunk: 629\n",
      "Non empty count in chunk: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 604\n",
      "Non empty count in chunk: 142\n",
      "Empty count in chunk: 633\n",
      "Non empty count in chunk: 113\n",
      "Empty count in chunk: 607\n",
      "Non empty count in chunk: 138\n",
      "Empty count in chunk: 607\n",
      "Non empty count in chunk: 139\n",
      "Empty count in chunk: 602\n",
      "Non empty count in chunk: 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 606\n",
      "Non empty count in chunk: 139\n",
      "Empty count in chunk: 591\n",
      "Non empty count in chunk: 154\n",
      "Empty count in chunk: 609\n",
      "Non empty count in chunk: 136\n",
      "Empty count in chunk: 622\n",
      "Non empty count in chunk: 123\n",
      "Empty count in chunk: 618\n",
      "Non empty count in chunk: 127\n",
      "Locality\n",
      "12373\n",
      "2540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 611\n",
      "Non empty count in chunk: 135\n",
      "Empty count in chunk: 627\n",
      "Non empty count in chunk: 119\n",
      "Empty count in chunk: 592\n",
      "Non empty count in chunk: 154\n",
      "Empty count in chunk: 653\n",
      "Non empty count in chunk: 93\n",
      "Empty count in chunk: 614\n",
      "Non empty count in chunk: 132\n",
      "Empty count in chunk: 589\n",
      "Non empty count in chunk: 157\n",
      "Empty count in chunk: 605\n",
      "Non empty count in chunk: 141\n",
      "Empty count in chunk: 603\n",
      "Non empty count in chunk: 143\n",
      "Empty count in chunk: 600\n",
      "Non empty count in chunk: 146\n",
      "Empty count in chunk: 578\n",
      "Non empty count in chunk: 168\n",
      "Empty count in chunk: 576\n",
      "Non empty count in chunk: 170\n",
      "Empty count in chunk: 588\n",
      "Non empty count in chunk: 157\n",
      "Empty count in chunk: 594\n",
      "Non empty count in chunk: 151\n",
      "Empty count in chunk: 614\n",
      "Non empty count in chunk: 132\n",
      "Empty count in chunk: 593\n",
      "Non empty count in chunk: 153\n",
      "Empty count in chunk: 593\n",
      "Non empty count in chunk: 152\n",
      "Empty count in chunk: 576\n",
      "Non empty count in chunk: 169\n",
      "Empty count in chunk: 605\n",
      "Non empty count in chunk: 140\n",
      "Empty count in chunk: 595\n",
      "Non empty count in chunk: 150\n",
      "Empty count in chunk: 603\n",
      "Non empty count in chunk: 142\n",
      "Locality\n",
      "12009\n",
      "2904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 487\n",
      "Non empty count in chunk: 105\n",
      "Empty count in chunk: 486\n",
      "Non empty count in chunk: 106\n",
      "Empty count in chunk: 499\n",
      "Non empty count in chunk: 93\n",
      "Empty count in chunk: 494\n",
      "Non empty count in chunk: 98\n",
      "Empty count in chunk: 475\n",
      "Non empty count in chunk: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 482\n",
      "Non empty count in chunk: 110\n",
      "Empty count in chunk: 476\n",
      "Non empty count in chunk: 116\n",
      "Empty count in chunk: 481\n",
      "Non empty count in chunk: 111\n",
      "Empty count in chunk: 465\n",
      "Non empty count in chunk: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 481\n",
      "Non empty count in chunk: 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 482\n",
      "Non empty count in chunk: 110\n",
      "Empty count in chunk: 464\n",
      "Non empty count in chunk: 128\n",
      "Empty count in chunk: 505\n",
      "Non empty count in chunk: 87\n",
      "Empty count in chunk: 484\n",
      "Non empty count in chunk: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 495\n",
      "Non empty count in chunk: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n",
      "/tmp/ipykernel_3223/1118464819.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  unique_names = dfTreesDRP[(dfTreesDRP['locality'].str.lower().str.contains(parish, na=False)) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 483\n",
      "Non empty count in chunk: 109\n",
      "Empty count in chunk: 472\n",
      "Non empty count in chunk: 120\n",
      "Empty count in chunk: 484\n",
      "Non empty count in chunk: 108\n",
      "Empty count in chunk: 465\n",
      "Non empty count in chunk: 127\n",
      "Empty count in chunk: 481\n",
      "Non empty count in chunk: 111\n",
      "Locality\n",
      "9641\n",
      "2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 471\n",
      "Non empty count in chunk: 121\n",
      "Empty count in chunk: 472\n",
      "Non empty count in chunk: 120\n",
      "Empty count in chunk: 482\n",
      "Non empty count in chunk: 110\n",
      "Empty count in chunk: 489\n",
      "Non empty count in chunk: 103\n",
      "Empty count in chunk: 453\n",
      "Non empty count in chunk: 140\n",
      "Empty count in chunk: 463\n",
      "Non empty count in chunk: 129\n",
      "Empty count in chunk: 466\n",
      "Non empty count in chunk: 126\n",
      "Empty count in chunk: 468\n",
      "Non empty count in chunk: 124\n",
      "Empty count in chunk: 463\n",
      "Non empty count in chunk: 129\n",
      "Empty count in chunk: 447\n",
      "Non empty count in chunk: 145\n",
      "Empty count in chunk: 472\n",
      "Non empty count in chunk: 120\n",
      "Empty count in chunk: 448\n",
      "Non empty count in chunk: 144\n",
      "Empty count in chunk: 495\n",
      "Non empty count in chunk: 97\n",
      "Empty count in chunk: 482\n",
      "Non empty count in chunk: 110\n",
      "Empty count in chunk: 466\n",
      "Non empty count in chunk: 126\n",
      "Empty count in chunk: 466\n",
      "Non empty count in chunk: 126\n",
      "Empty count in chunk: 469\n",
      "Non empty count in chunk: 123\n",
      "Empty count in chunk: 454\n",
      "Non empty count in chunk: 138\n",
      "Empty count in chunk: 446\n",
      "Non empty count in chunk: 146\n",
      "Empty count in chunk: 462\n",
      "Non empty count in chunk: 130\n",
      "Locality\n",
      "9334\n",
      "2507\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "dfTreesDRP = pd.read_csv('TreesPortugueseTerritoryDropped.csv')\n",
    "\n",
    "def process_chunkv1(chunk):\n",
    "    chunk['scientificNames'] = chunk.apply(check_locality, axis=1)\n",
    "    empty_count = (chunk['scientificNames'] == '').sum()\n",
    "    print(f'Empty count in chunk: {empty_count}')\n",
    "    non_empty_count = (chunk['scientificNames'] != '').sum()\n",
    "    print(f'Non empty count in chunk: {non_empty_count}')\n",
    "    return chunk\n",
    "\n",
    "def process_chunkv2(chunk):\n",
    "    chunk['scientificNames'] = chunk.apply(check_locality2, axis=1)\n",
    "    empty_count = (chunk['scientificNames'] == '').sum()\n",
    "    print(f'Empty count in chunk: {empty_count}')\n",
    "    non_empty_count = (chunk['scientificNames'] != '').sum()\n",
    "    print(f'Non empty count in chunk: {non_empty_count}')\n",
    "    return chunk\n",
    "\n",
    "for _year in range(2001, 2013):\n",
    "\n",
    "    if _year != 2022:\n",
    "\n",
    "        dfFires = pd.read_csv(f\"Dataset/b{_year}.csv\")\n",
    "        num_chunks = 20\n",
    "\n",
    "        # Split the DataFrame into smaller chunks\n",
    "        chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "        # Create a ProcessPoolExecutor\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:\n",
    "            # Use the executor to map the function to the chunks\n",
    "            chunks = list(executor.map(process_chunkv1, chunks))\n",
    "\n",
    "        # Concatenate the chunks back into a single DataFrame\n",
    "        dfFires = pd.concat(chunks)\n",
    "\n",
    "        dfFires.to_csv(f'DatasetWTrees/PreviousVersions/{_year}_checklocality.csv', index=False)\n",
    "\n",
    "        print(\"Locality\")\n",
    "        empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "        print(empty_count)\n",
    "\n",
    "        non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "        print(non_empty_count)\n",
    "\n",
    "    dfFires = pd.read_csv(f\"DatasetWTrees/PreviousVersions/{_year}_checklocality.csv\")\n",
    "\n",
    "    num_chunks = 20\n",
    "\n",
    "    # Split the DataFrame into smaller chunks\n",
    "    chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:\n",
    "        # Use the executor to map the function to the chunks\n",
    "        chunks = list(executor.map(process_chunkv2, chunks))\n",
    "\n",
    "    dfFires = pd.concat(chunks)\n",
    "\n",
    "    dfFires.to_csv(f'DatasetWTrees/PreviousVersions/{_year}_checklocality2.csv', index=False)\n",
    "\n",
    "    print(\"Locality\")\n",
    "    empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "    print(empty_count)\n",
    "\n",
    "    non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "    print(non_empty_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
