{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "\n",
    "dfTreesDRP = pd.read_csv('TreesPortugueseTerritoryDropped.csv')\n",
    "\n",
    "def DistanceTwoPoints(lat1, lon1, lat2, lon2):\n",
    "    R = 6371e3  # Radius of the Earth in meters\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(delta_phi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    return R * c  # Distance in meters\n",
    "\n",
    "\n",
    "def check_district(row, precision=1000):\n",
    "    district = str(row['district']).lower()\n",
    "    lat1 = row['latitude']\n",
    "    lon1 = row['longitude']\n",
    "    \n",
    "    # Filter dfTreesDRP based on 'locality' and 'stateProvince'\n",
    "    filtered_df = dfTreesDRP[(dfTreesDRP['stateProvince'].str.lower() == district)]\n",
    "    \n",
    "    # Calculate the distance for each row in the filtered DataFrame\n",
    "    filtered_df['distance'] = filtered_df.apply(lambda x: DistanceTwoPoints(lat1, lon1, x['decimalLatitude'], x['decimalLongitude']), axis=1)\n",
    "    \n",
    "    # Filter the DataFrame based on the distance\n",
    "    close_points_df = filtered_df[filtered_df['distance'] < precision]\n",
    "    \n",
    "    # Get the unique 'scientificName' values, excluding NaN values\n",
    "    unique_names = close_points_df['scientificName'].dropna().unique()\n",
    "\n",
    "    # If 'scientificNames' exists in row and is not NaN, append unique names if they don't exist\n",
    "    if 'scientificNames' in row and pd.notna(row['scientificNames']):\n",
    "        existing_names = str(row['scientificNames']).split('; ')\n",
    "        for name in unique_names:\n",
    "            if name not in existing_names:\n",
    "                existing_names.append(name)\n",
    "        return '; '.join(existing_names)\n",
    "    \n",
    "    # If 'scientificNames' is NaN, just return the unique names\n",
    "    return '; '.join(unique_names)\n",
    "\n",
    "def process_chunkv1(chunk):\n",
    "    chunk['scientificNames'] = chunk.apply(check_district, axis=1)\n",
    "    empty_count = (chunk['scientificNames'] == '').sum()\n",
    "    print(f'Empty count in chunk: {empty_count}')\n",
    "    non_empty_count = (chunk['scientificNames'] != '').sum()\n",
    "    print(f'Non empty count in chunk: {non_empty_count}')\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ori/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 209\n",
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 209\n",
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 209\n",
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 208\n",
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 208\n",
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 208\n",
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 208\n",
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 208\n",
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 208\n",
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 208\n",
      "Empty count in chunk: 1\n",
      "Non empty count in chunk: 207\n",
      "Empty count in chunk: 0\n",
      "Non empty count in chunk: 208\n",
      "District\n",
      "1\n",
      "2498\n"
     ]
    }
   ],
   "source": [
    "for _year in range(2001, 2023):\n",
    "    dfFires = pd.read_csv(f\"DatasetWTrees/PreviousVersions/{_year}_namissing.csv\")\n",
    "\n",
    "    #num_chunks = 20\n",
    "\n",
    "    print(len(dfFires))\n",
    "\n",
    "    num_chunks = int(((1/200) * len(dfFires)))\n",
    "\n",
    "    print(num_chunks)\n",
    "    # Split the DataFrame into smaller chunks\n",
    "    chunks = np.array_split(dfFires, num_chunks)\n",
    "\n",
    "    # Create a ProcessPoolExecutor\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:\n",
    "        # Use the executor to map the function to the chunks\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            print(f\"{_year} - Chunk: \", i)\n",
    "            chunk = executor.submit(process_chunkv1, chunk).result()\n",
    "            chunk.to_csv(f'DatasetWTrees/PreviousVersions/check_byCoord/{_year}_chunk_{i}.csv', index=False)\n",
    "            chunks[i] = chunk\n",
    "\n",
    "    # Concatenate the chunks back into a single DataFrame\n",
    "    dfFires = pd.concat(chunks)\n",
    "\n",
    "    dfFires.to_csv(f'DatasetWTrees/PreviousVersions/{_year}_checkDistrict.csv', index=False)\n",
    "\n",
    "    print(\"District\")\n",
    "    empty_count = (dfFires['scientificNames'] == '').sum()\n",
    "    print(empty_count)\n",
    "\n",
    "    non_empty_count = (dfFires['scientificNames'] != '').sum()\n",
    "    print(non_empty_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
