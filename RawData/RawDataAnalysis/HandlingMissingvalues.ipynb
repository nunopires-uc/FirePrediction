{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10457/1817075740.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "_year = 2018\n",
    "dfMissing = pd.read_csv(f'error_rows{_year}.csv')\n",
    "print(len(dfMissing))\n",
    "for r in range(0, len(dfMissing)):\n",
    "    row = dfMissing.iloc[r]\n",
    "\n",
    "    DIA = row['DIA']\n",
    "    MES = row['MES']\n",
    "    HORA = row['HORA']\n",
    "    LAT = row['LAT']\n",
    "    LON = row['LON']\n",
    "    ANO = row['ANO']\n",
    "    DISTRICTO = row['DISTRITO']\n",
    "    CONCELHO = row['CONCELHO']\n",
    "    FREGUESIA = row['FREGUESIA']\n",
    "    CAUSA = row['TIPOCAUSA']\n",
    "    LOCAL = row['LOCAL']\n",
    "\n",
    "    MES = \"0\" + str(MES) if MES < 10 else str(MES)\n",
    "    DIA = \"0\" + str(DIA) if DIA < 10 else str(DIA)\n",
    "\n",
    "    _fileName = f\"{DIA}_{MES}_{HORA}_{LAT}_{LON}.csv.csv\"\n",
    "\n",
    "    _fileName_radiation = f\"{DIA}_{MES}_{HORA}_{LAT}_{LON}_radiation.csv\"\n",
    "\n",
    "    _DATA = f\"{ANO}-{MES}-{DIA}\"\n",
    "\n",
    "\n",
    "    #RawData/RawDataAnalysis/MissingFiles2012\n",
    "    url_rad = f\"https://archive-api.open-meteo.com/v1/archive?latitude={LAT}&longitude={LON}&start_date={_DATA}&end_date={_DATA}&hourly=shortwave_radiation,direct_radiation,diffuse_radiation,direct_normal_irradiance,global_tilted_irradiance,terrestrial_radiation,shortwave_radiation_instant,direct_radiation_instant,diffuse_radiation_instant,direct_normal_irradiance_instant,global_tilted_irradiance_instant,terrestrial_radiation_instant\"\n",
    "    #url = f\"https://archive-api.open-meteo.com/v1/archive?latitude={LAT}&longitude={LON}&start_date={_DATA}&end_date={_DATA}&hourly=temperature_2m,relative_humidity_2m,dew_point_2m,apparent_temperature,precipitation,rain,snowfall,snow_depth,weather_code,pressure_msl,surface_pressure,cloud_cover,cloud_cover_low,cloud_cover_mid,cloud_cover_high,et0_fao_evapotranspiration,vapour_pressure_deficit,wind_speed_10m,wind_speed_100m,wind_direction_10m,wind_direction_100m,wind_gusts_10m,soil_temperature_0_to_7cm,soil_temperature_7_to_28cm,soil_temperature_28_to_100cm,soil_temperature_100_to_255cm,soil_moisture_0_to_7cm,soil_moisture_7_to_28cm,soil_moisture_28_to_100cm,soil_moisture_100_to_255cm,is_day,sunshine_duration,shortwave_radiation_instant,direct_radiation_instant,diffuse_radiation_instant,direct_normal_irradiance_instant,global_tilted_irradiance_instant,terrestrial_radiation_instant&timezone=GMT\"\n",
    "    #response = requests.get(url)\n",
    "    response_rad = requests.get(url_rad)\n",
    "\n",
    "    #print(response.status_code)\n",
    "    print(response_rad.status_code)\n",
    "\n",
    "    if((response_rad.status_code == 200)):\n",
    "        #data = response.json()\n",
    "        data_rad = response_rad.json()\n",
    "\n",
    "        #df = pd.json_normalize(data)\n",
    "        #df.to_csv(f\"MissingFiles{_year}/{_fileName}\", index=False)\n",
    "\n",
    "        df_rad = pd.json_normalize(data_rad)\n",
    "        df_rad.to_csv(f\"MissingFiles{_year}/{_fileName_radiation}\", index=False)\n",
    "    else:\n",
    "        print(\"Error row:\", str(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['latitude', 'longitude', 'generationtime_ms', 'utc_offset_seconds', 'timezone', 'timezone_abbreviation', 'elevation', 'hourly_units.time', 'hourly_units.shortwave_radiation', 'hourly_units.direct_radiation', 'hourly_units.diffuse_radiation', 'hourly_units.direct_normal_irradiance', 'hourly_units.global_tilted_irradiance', 'hourly_units.terrestrial_radiation', 'hourly_units.shortwave_radiation_instant', 'hourly_units.direct_radiation_instant', 'hourly_units.diffuse_radiation_instant', 'hourly_units.direct_normal_irradiance_instant', 'hourly_units.global_tilted_irradiance_instant', 'hourly_units.terrestrial_radiation_instant', 'hourly.time', 'hourly.shortwave_radiation', 'hourly.direct_radiation', 'hourly.diffuse_radiation', 'hourly.direct_normal_irradiance', 'hourly.global_tilted_irradiance', 'hourly.terrestrial_radiation', 'hourly.shortwave_radiation_instant', 'hourly.direct_radiation_instant', 'hourly.diffuse_radiation_instant', 'hourly.direct_normal_irradiance_instant', 'hourly.global_tilted_irradiance_instant', 'hourly.terrestrial_radiation_instant']\n",
      "['hourly.shortwave_radiation', 'hourly.direct_radiation', 'hourly.diffuse_radiation', 'hourly.direct_normal_irradiance', 'hourly.global_tilted_irradiance', 'hourly.terrestrial_radiation']\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "root_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "_RAWFIRESPATH = f\"{root_dir}/RawData/Historical_FiresRAW\"\n",
    "\n",
    "_year = 2005\n",
    "_file = f\"{_RAWFIRESPATH}/{_year}/2005-01-01_37.7388357_-8.750062888101874.csv\"\n",
    "df = pd.read_csv(f\"{_file}\")\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "columns_to_remove = [col for col in column_names if 'hourly_units' in col]\n",
    "columns_to_remove.extend(['latitude', 'longitude', 'generationtime_ms', 'utc_offset_seconds', 'timezone', 'timezone_abbreviation'])\n",
    "\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "\n",
    "updated_column_names = df.columns.tolist()\n",
    "\n",
    "_file_radiation = _file.replace(\".csv\", \"_radiation.csv\")\n",
    "df = pd.read_csv(f\"{_file_radiation}\")\n",
    "\n",
    "df = pd.read_csv(f\"{_file_radiation}\")\n",
    "column_names = df.columns.tolist()\n",
    "print(column_names)\n",
    "\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "columns_to_remove = [col for col in column_names if 'hourly_units' in col]\n",
    "columns_to_remove.extend(['latitude', 'longitude', 'generationtime_ms', 'utc_offset_seconds', 'timezone', 'timezone_abbreviation', 'elevation', 'hourly.time', 'hourly.global_tilted_irradiance_instant', 'hourly.diffuse_radiation_instant', 'hourly.terrestrial_radiation_instant', 'hourly.direct_radiation_instant', 'hourly.shortwave_radiation_instant', 'hourly.direct_normal_irradiance_instant'])\n",
    "\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "\n",
    "updated_column_names_radiation = df.columns.tolist()\n",
    "print(updated_column_names_radiation)\n",
    "\n",
    "set1 = set(updated_column_names_radiation)\n",
    "set2 = set(updated_column_names)\n",
    "\n",
    "common_elements = set1 & set2\n",
    "\n",
    "print(common_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [year, date, district, municipality, parish, local, latitude, longitude, cause, elevation, hourly.time, hourly.temperature_2m, hourly.relative_humidity_2m, hourly.dew_point_2m, hourly.apparent_temperature, hourly.precipitation, hourly.rain, hourly.snowfall, hourly.snow_depth, hourly.weather_code, hourly.pressure_msl, hourly.surface_pressure, hourly.cloud_cover, hourly.cloud_cover_low, hourly.cloud_cover_mid, hourly.cloud_cover_high, hourly.et0_fao_evapotranspiration, hourly.vapour_pressure_deficit, hourly.wind_speed_10m, hourly.wind_speed_100m, hourly.wind_direction_10m, hourly.wind_direction_100m, hourly.wind_gusts_10m, hourly.soil_temperature_0_to_7cm, hourly.soil_temperature_7_to_28cm, hourly.soil_temperature_28_to_100cm, hourly.soil_temperature_100_to_255cm, hourly.soil_moisture_0_to_7cm, hourly.soil_moisture_7_to_28cm, hourly.soil_moisture_28_to_100cm, hourly.soil_moisture_100_to_255cm, hourly.is_day, hourly.sunshine_duration, hourly.shortwave_radiation_instant, hourly.direct_radiation_instant, hourly.diffuse_radiation_instant, hourly.direct_normal_irradiance_instant, hourly.global_tilted_irradiance_instant, hourly.terrestrial_radiation_instant, hourly.shortwave_radiation, hourly.direct_radiation, hourly.diffuse_radiation, hourly.direct_normal_irradiance, hourly.global_tilted_irradiance, hourly.terrestrial_radiation]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 55 columns]\n",
      "DISTRITO                 SantarÃ©m\n",
      "TIPO                    Florestal\n",
      "ANO                          2018\n",
      "AREAPOV                       1.0\n",
      "AREAMATO                   1.3118\n",
      "                          ...    \n",
      "AREASFICHEIROPRJ_GTF          NaN\n",
      "AREASFICHEIROSBN_GTF          NaN\n",
      "AREASFICHEIROSBX_GTF          NaN\n",
      "AREASFICHEIROSHX_GTF          NaN\n",
      "AREASFICHEIROZIP_SAA          NaN\n",
      "Name: 0, Length: 76, dtype: object\n",
      "20_02_12_39.1914830001195_-8.78038699997796.csv.csv 20_02_12_39.1914830001195_-8.78038699997796_radiation.csv\n",
      "True True\n",
      "58.0\n",
      "16.8\n",
      "2018-02-20T12:00\n"
     ]
    }
   ],
   "source": [
    "_year = 2018\n",
    "\n",
    "df = pd.read_csv(\"b2018y.csv\")\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "dfsourcex = pd.read_csv(f'error_rows{_year}.csv')\n",
    "\n",
    "for r in range(0, len(dfsourcex)):\n",
    "\n",
    "    row = dfsourcex.iloc[r]\n",
    "\n",
    "\n",
    "    print(row)\n",
    "\n",
    "    DIA = row['DIA']\n",
    "    MES = row['MES']\n",
    "    HORA = row['HORA']\n",
    "    LAT = row['LAT']\n",
    "    LON = row['LON']\n",
    "    ANO = row['ANO']\n",
    "    DISTRICTO = row['DISTRITO']\n",
    "    CONCELHO = row['CONCELHO']\n",
    "    FREGUESIA = row['FREGUESIA']\n",
    "    CAUSA = row['TIPOCAUSA']\n",
    "    LOCAL = row['LOCAL']\n",
    "\n",
    "    MES = \"0\" + str(MES) if MES < 10 else str(MES)\n",
    "    DIA = \"0\" + str(DIA) if DIA < 10 else str(DIA)\n",
    "\n",
    "    if pd.isna(LOCAL):\n",
    "        LOCAL = 'NC'\n",
    "\n",
    "    if pd.isna(CAUSA):\n",
    "        CAUSA = 'NC'\n",
    "\n",
    "    MeteorologyFile = False\n",
    "    RadiationFile = False\n",
    "\n",
    "\n",
    "    _fileName = f\"{DIA}_{MES}_{HORA}_{LAT}_{LON}.csv.csv\"\n",
    "\n",
    "    _fileName_radiation = f\"{DIA}_{MES}_{HORA}_{LAT}_{LON}_radiation.csv\"\n",
    "\n",
    "    print(_fileName, _fileName_radiation)\n",
    "\n",
    "    # MissingFiles{_year}/{_fileName_radiation}.csv\n",
    "    isExistMeteorology = os.path.isfile(f'MissingFiles{_year}/{_fileName}')\n",
    "    if(isExistMeteorology):\n",
    "        MeteorologyFile = True\n",
    "    else:\n",
    "        row_df = pd.DataFrame(row).transpose()  # Convert row (Series) to DataFrame\n",
    "        row_df.to_csv(f'error_rowsX{_year}.csv', mode='a', header=False, index=False)\n",
    "        \n",
    "        continue\n",
    "\n",
    "    isExistRadiation = os.path.isfile(f'MissingFiles{_year}/{_fileName_radiation}')\n",
    "    if(isExistRadiation):\n",
    "        RadiationFile = True\n",
    "    else:\n",
    "        row_df = pd.DataFrame(row).transpose()  # Convert row (Series) to DataFrame\n",
    "        row_df.to_csv(f'error_rowsX{_year}.csv', mode='a', header=False, index=False)\n",
    "        \n",
    "        continue\n",
    "\n",
    "    print(isExistMeteorology, RadiationFile)\n",
    "\n",
    "    if(MeteorologyFile and RadiationFile):\n",
    "        try:\n",
    "            dfMet = pd.read_csv(f\"MissingFiles{_year}/{_fileName}\")\n",
    "            dfRad = pd.read_csv(f\"MissingFiles{_year}/{_fileName_radiation}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            row_df = pd.DataFrame(row).transpose()  # Convert row (Series) to DataFrame\n",
    "            row_df.to_csv(f'error_rowsX{_year}.csv', mode='a', header=False, index=False)\n",
    "            \n",
    "            continue\n",
    "\n",
    "        print(dfMet['elevation'].iloc[0])\n",
    "\n",
    "        list_from_string = ast.literal_eval(dfMet[updated_column_names[2]].iloc[0])[HORA]\n",
    "\n",
    "        print(list_from_string)\n",
    "\n",
    "        list_from_string = ast.literal_eval(dfMet[updated_column_names[1]].iloc[0])[HORA]\n",
    "\n",
    "        print(list_from_string)\n",
    "\n",
    "        new_data = {\n",
    "            'year': ANO,\n",
    "            'date': f\"{_DATA}\",\n",
    "            'district': DISTRICTO,\n",
    "            'municipality': CONCELHO,\n",
    "            'parish': FREGUESIA,\n",
    "            'local': LOCAL,\n",
    "            'latitude': LAT,\n",
    "            'longitude': LON,\n",
    "            'cause': CAUSA,\n",
    "            'elevation': dfMet['elevation'].iloc[0]\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            for i in range(1, len(updated_column_names)):\n",
    "                new_data[updated_column_names[i]] = ast.literal_eval(dfMet[updated_column_names[i]].iloc[0])[HORA]\n",
    "        except Exception as e:\n",
    "            print(\"->\", e)\n",
    "\n",
    "        try:\n",
    "            for i in range(0, len(updated_column_names_radiation)):\n",
    "                new_data[updated_column_names_radiation[i]] = ast.literal_eval(dfRad[updated_column_names_radiation[i]].iloc[0])[HORA]\n",
    "        except Exception as e:\n",
    "            print(\"-x\", e)\n",
    "\n",
    "        new_df = pd.DataFrame(new_data, index=[0])\n",
    "\n",
    "        new_df.to_csv('b2018y.csv', mode='a', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
