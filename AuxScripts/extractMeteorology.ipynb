{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+----------------------+---------+----------+\n| Column               | Found   | Expected |\n+----------------------+---------+----------+\n| AREAPOV              | float64 | int64    |\n| AREASFICHEIRODBF_GTF | object  | float64  |\n| AREASFICHEIROPRJ_GTF | object  | float64  |\n| AREASFICHEIROSHP_GTF | object  | float64  |\n| AREASFICHEIROSHX_GTF | object  | float64  |\n| AREASFICHEIROS_GTF   | object  | float64  |\n| AREASFICHEIROZIP_SAA | object  | float64  |\n| CAUSA                | float64 | int64    |\n| DURACAO              | float64 | int64    |\n| OPERADOR             | object  | int64    |\n| PERIMETRO            | object  | float64  |\n+----------------------+---------+----------+\n\nThe following columns also raised exceptions on conversion:\n\n- AREASFICHEIRODBF_GTF\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.dbf'\")\n- AREASFICHEIROPRJ_GTF\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.prj'\")\n- AREASFICHEIROSHP_GTF\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.shp'\")\n- AREASFICHEIROSHX_GTF\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.shx'\")\n- AREASFICHEIROS_GTF\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.kml'\")\n- AREASFICHEIROZIP_SAA\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.zip'\")\n- OPERADOR\n  ValueError(\"invalid literal for int() with base 10: 'sigo'\")\n- PERIMETRO\n  ValueError(\"could not convert string to float: 'Mata Nacional das Dunas de Vila Real de Santo Antonio'\")\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'AREAPOV': 'float64',\n       'AREASFICHEIRODBF_GTF': 'object',\n       'AREASFICHEIROPRJ_GTF': 'object',\n       'AREASFICHEIROSHP_GTF': 'object',\n       'AREASFICHEIROSHX_GTF': 'object',\n       'AREASFICHEIROS_GTF': 'object',\n       'AREASFICHEIROZIP_SAA': 'object',\n       'CAUSA': 'float64',\n       'DURACAO': 'float64',\n       'OPERADOR': 'object',\n       'PERIMETRO': 'object'}\n\nto the call to `read_csv`/`read_table`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../RawData/Historical_FiresRAW/icnf_2021.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/dataframe/core.py:1590\u001b[0m, in \u001b[0;36m_Frame.head\u001b[0;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;66;03m# No need to warn if we're already looking at all partitions\u001b[39;00m\n\u001b[1;32m   1589\u001b[0m safe \u001b[38;5;241m=\u001b[39m npartitions \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnpartitions\n\u001b[0;32m-> 1590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpartitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpartitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/dataframe/core.py:1624\u001b[0m, in \u001b[0;36m_Frame._head\u001b[0;34m(self, n, npartitions, compute, safe)\u001b[0m\n\u001b[1;32m   1619\u001b[0m result \u001b[38;5;241m=\u001b[39m new_dd_object(\n\u001b[1;32m   1620\u001b[0m     graph, name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions[npartitions]]\n\u001b[1;32m   1621\u001b[0m )\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[0;32m-> 1624\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/base.py:379\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/base.py:665\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 665\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/dataframe/io/csv.py:142\u001b[0m, in \u001b[0;36mCSVFunctionWrapper.__call__\u001b[0;34m(self, part)\u001b[0m\n\u001b[1;32m    139\u001b[0m         rest_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m columns\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Call `pandas_read_text`\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_read_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrest_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project_after_read:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/dataframe/io/csv.py:197\u001b[0m, in \u001b[0;36mpandas_read_text\u001b[0;34m(reader, b, header, kwargs, dtypes, columns, write_header, enforce, path)\u001b[0m\n\u001b[1;32m    195\u001b[0m df \u001b[38;5;241m=\u001b[39m reader(bio, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtypes:\n\u001b[0;32m--> 197\u001b[0m     \u001b[43mcoerce_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enforce \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m(columns)):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns do not match\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mcolumns, columns)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/dataframe/io/csv.py:298\u001b[0m, in \u001b[0;36mcoerce_dtypes\u001b[0;34m(df, dtypes)\u001b[0m\n\u001b[1;32m    294\u001b[0m rule \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m61\u001b[39m)\n\u001b[1;32m    295\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatched dtypes found in `pd.read_csv`/`pd.read_table`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    296\u001b[0m     rule\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, [dtype_msg, date_msg]))\n\u001b[1;32m    297\u001b[0m )\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+----------------------+---------+----------+\n| Column               | Found   | Expected |\n+----------------------+---------+----------+\n| AREAPOV              | float64 | int64    |\n| AREASFICHEIRODBF_GTF | object  | float64  |\n| AREASFICHEIROPRJ_GTF | object  | float64  |\n| AREASFICHEIROSHP_GTF | object  | float64  |\n| AREASFICHEIROSHX_GTF | object  | float64  |\n| AREASFICHEIROS_GTF   | object  | float64  |\n| AREASFICHEIROZIP_SAA | object  | float64  |\n| CAUSA                | float64 | int64    |\n| DURACAO              | float64 | int64    |\n| OPERADOR             | object  | int64    |\n| PERIMETRO            | object  | float64  |\n+----------------------+---------+----------+\n\nThe following columns also raised exceptions on conversion:\n\n- AREASFICHEIRODBF_GTF\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.dbf'\")\n- AREASFICHEIROPRJ_GTF\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.prj'\")\n- AREASFICHEIROSHP_GTF\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.shp'\")\n- AREASFICHEIROSHX_GTF\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.shx'\")\n- AREASFICHEIROS_GTF\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.kml'\")\n- AREASFICHEIROZIP_SAA\n  ValueError(\"could not convert string to float: 'http://fogos.icnf.pt/sgif2010/ficheiroskml/AA_AG1211131.zip'\")\n- OPERADOR\n  ValueError(\"invalid literal for int() with base 10: 'sigo'\")\n- PERIMETRO\n  ValueError(\"could not convert string to float: 'Mata Nacional das Dunas de Vila Real de Santo Antonio'\")\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'AREAPOV': 'float64',\n       'AREASFICHEIRODBF_GTF': 'object',\n       'AREASFICHEIROPRJ_GTF': 'object',\n       'AREASFICHEIROSHP_GTF': 'object',\n       'AREASFICHEIROSHX_GTF': 'object',\n       'AREASFICHEIROS_GTF': 'object',\n       'AREASFICHEIROZIP_SAA': 'object',\n       'CAUSA': 'float64',\n       'DURACAO': 'float64',\n       'OPERADOR': 'object',\n       'PERIMETRO': 'object'}\n\nto the call to `read_csv`/`read_table`."
     ]
    }
   ],
   "source": [
    "df = dd.read_csv('../RawData/Historical_FiresRAW/icnf_2021.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 DISTRITO       TIPO   ANO  AREAPOV  AREAMATO  AREAAGRIC  \\\n",
      "0           0     Faro  Florestal  2021      0.0     0.002     0.0000   \n",
      "1           1     Faro  Florestal  2021      0.0     0.007     0.0000   \n",
      "2           2     Faro   Agrícola  2021      0.0     0.000     0.0328   \n",
      "3           3     Faro   Agrícola  2021      0.0     0.000     0.3000   \n",
      "4           4     Faro  Florestal  2021      0.0     0.474     0.0000   \n",
      "\n",
      "   AREATOTAL  REACENDIMENTOS  QUEIMADA  ...  AREASFICHEIROS_GTF  \\\n",
      "0     0.0020               0         0  ...                 NaN   \n",
      "1     0.0070               0         0  ...                 NaN   \n",
      "2     0.0328               0         0  ...                 NaN   \n",
      "3     0.3000               0         0  ...                 NaN   \n",
      "4     0.4740               0         0  ...                 NaN   \n",
      "\n",
      "   FICHEIROIMAGEM_GNR  AREASFICHEIROSHP_GTF  AREASFICHEIROSHPXML_GTF  \\\n",
      "0                 NaN                   NaN                      NaN   \n",
      "1                 NaN                   NaN                      NaN   \n",
      "2                 NaN                   NaN                      NaN   \n",
      "3                 NaN                   NaN                      NaN   \n",
      "4                 NaN                   NaN                      NaN   \n",
      "\n",
      "   AREASFICHEIRODBF_GTF  AREASFICHEIROPRJ_GTF AREASFICHEIROSBN_GTF  \\\n",
      "0                   NaN                   NaN                  NaN   \n",
      "1                   NaN                   NaN                  NaN   \n",
      "2                   NaN                   NaN                  NaN   \n",
      "3                   NaN                   NaN                  NaN   \n",
      "4                   NaN                   NaN                  NaN   \n",
      "\n",
      "  AREASFICHEIROSBX_GTF AREASFICHEIROSHX_GTF AREASFICHEIROZIP_SAA  \n",
      "0                  NaN                  NaN                  NaN  \n",
      "1                  NaN                  NaN                  NaN  \n",
      "2                  NaN                  NaN                  NaN  \n",
      "3                  NaN                  NaN                  NaN  \n",
      "4                  NaN                  NaN                  NaN  \n",
      "\n",
      "[5 rows x 77 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../RawData/Historical_FiresRAW/icnf_2021.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of instances: 865066\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory containing the CSV files\n",
    "dir_path = '../RawData/Historical_FiresRAW/'\n",
    "\n",
    "# Initialize total count\n",
    "total_count = 0\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    # Check if the file is a CSV file\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read the CSV file with dtype set to object to avoid DtypeWarnings\n",
    "        df = pd.read_csv(os.path.join(dir_path, filename), dtype='object')\n",
    "        # Add the number of instances (rows) to the total count\n",
    "        total_count += df.shape[0]\n",
    "\n",
    "print(f'Total number of instances: {total_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TIPO   ANO  AREAMATO  AREATOTAL  QUEIMADA  FALSOALARME HORAALERTA  \\\n",
      "5530  Florestal  2021       0.0        0.0         0            0      13:24   \n",
      "\n",
      "                                                  LOCAL CONCELHO  \\\n",
      "5530  AV GENERAL MARIO FIRMINO MIGUEL 2710-553_SINTR...   Sintra   \n",
      "\n",
      "                              FREGUESIA      X       Y  DIA  MES  HORA  \\\n",
      "5530  Sintra (Santa Maria e São Miguel)  92582  204785    5    9    13   \n",
      "\n",
      "            LAT      LON  \n",
      "5530  38.804078 -9.36967  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('../RawData/Historical_FiresRAW/icnf_2021.csv')\n",
    "\n",
    "# Get a random row\n",
    "random_row = df.sample(1)\n",
    "\n",
    "# Print the specified columns\n",
    "print(random_row[['TIPO', 'ANO', 'AREAMATO', 'AREATOTAL',\n",
    "                   'QUEIMADA', 'FALSOALARME', 'HORAALERTA', \n",
    "                   'LOCAL', 'CONCELHO', 'FREGUESIA', \n",
    "                   'X', 'Y', 'DIA', \n",
    "                   'MES', 'HORA', 'LAT', 'LON']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           TIPO   ANO  AREAMATO  AREATOTAL  QUEIMADA  FALSOALARME HORAALERTA  \\\n",
    "1277  Florestal  2021    0.0003     0.0003         0            0      11:33   \n",
    "\n",
    "                                           LOCAL   CONCELHO  FREGUESIA  \\\n",
    "1277  Quinta da Fonte Nova (EN233 (EN233) Km 61)  Penamacor  Penamacor   \n",
    "\n",
    "           X       Y  DIA  MES  HORA        LAT      LON  \n",
    "1277  281256  355640   20    5    11  40.165448 -7.17927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import urllib.request\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "        \n",
    "try: \n",
    "  ResultBytes = urllib.request.urlopen(\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/40.165448%2C%20-7.17927/2021-09-05/2021-09-05?unitGroup=metric&include=hours&key=|APIKEY|&contentType=csv\")\n",
    "  \n",
    "  # Parse the results as CSV\n",
    "  CSVText = csv.reader(codecs.iterdecode(ResultBytes, 'utf-8'))\n",
    "\n",
    "  with open('output.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(CSVText)\n",
    "        \n",
    "except urllib.error.HTTPError  as e:\n",
    "  ErrorInfo= e.read().decode() \n",
    "  print('Error code: ', e.code, ErrorInfo)\n",
    "  sys.exit()\n",
    "except  urllib.error.URLError as e:\n",
    "  ErrorInfo= e.read().decode() \n",
    "  print('Error code: ', e.code,ErrorInfo)\n",
    "  sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'datetime', 'temp', 'feelslike', 'dew', 'humidity', 'precip', 'precipprob', 'preciptype', 'snow', 'snowdepth', 'windgust', 'windspeed', 'winddir', 'sealevelpressure', 'cloudcover', 'visibility', 'solarradiation', 'solarenergy', 'uvindex', 'severerisk', 'conditions', 'icon', 'stations']\n",
      "    temp  dew  humidity  precip  precipprob  preciptype  snow  snowdepth  \\\n",
      "10  20.9  8.2     43.95       0           0         NaN   NaN        NaN   \n",
      "\n",
      "    windgust  windspeed  winddir  sealevelpressure  cloudcover  visibility  \\\n",
      "10       NaN       11.7    122.0            1016.6        62.7         NaN   \n",
      "\n",
      "    solarradiation  solarenergy  uvindex  severerisk        conditions  \n",
      "10             347          1.2        3         NaN  Partially cloudy  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('output.csv')\n",
    "\n",
    "# Print all column names\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Get a random row\n",
    "random_row = df.sample(1)\n",
    "\n",
    "# Print the random row\n",
    "print(random_row[['temp', 'dew', 'humidity', 'precip', 'precipprob', 'preciptype', 'snow', 'snowdepth', 'windgust', 'windspeed', 'winddir', 'sealevelpressure', 'cloudcover', 'visibility', 'solarradiation', 'solarenergy', 'uvindex', 'severerisk', 'conditions']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
